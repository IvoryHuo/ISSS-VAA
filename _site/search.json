[
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html",
    "title": "Hands-on Exercise 1",
    "section": "",
    "text": "The code chunk below uses p_load() of pacman package to check if tidyverse packages are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)\n\n\n\n\n\nexam_data <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\nNote that read_csv can deal with attribute with space in names, while read.csv cannot.\nFor example, the attribute name is “Project Name”. Using read.csv, then the name will be read as “Project.Name”. Using read_csv, the name will be read as “Project Name”, the space is retained back."
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-no_of_stu-for-different-races",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-no_of_stu-for-different-races",
    "title": "Hands-on Exercise 1",
    "section": "Plotting No_of_Stu for Different Races",
    "text": "Plotting No_of_Stu for Different Races\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar()"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-math-grades-for-students-of-different-gender-in-each-class",
    "href": "Hands-on_Ex/Hands-on_Ex01/Hands-on_Ex01.html#plotting-math-grades-for-students-of-different-gender-in-each-class",
    "title": "Hands-on Exercise 1",
    "section": "Plotting Math Grades for students of different gender in each class",
    "text": "Plotting Math Grades for students of different gender in each class\n\nggplot(data = exam_data,\n       aes(x= CLASS,y=MATHS)) +\n  geom_boxplot() +\n  facet_grid(~GENDER)\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x= CLASS,y=MATHS)) +\n  geom_boxplot() +\n  facet_grid(rows = vars(GENDER))\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x= GENDER,y=MATHS)) +\n  geom_boxplot() +\n  facet_grid(rows = vars(GENDER),cols = vars(CLASS))+\n  theme(axis.text=element_text(size = 6))\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = RACE)) +\n  geom_bar() +\n  coord_flip()+\n  theme_minimal()+\n  theme(panel.background = element_rect(fill = \"lightblue\", color = \"white\"))\n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = reorder(RACE,RACE,function(x)-length(x)))) +\n  geom_bar()+\n  labs(y = \"No. of Pupils\",x = \"Race\") \n\n\n\n\n\nggplot(data = exam_data,\n       aes(x = fct_infreq(RACE)))+\n  geom_text(stat = 'count',aes(label = after_stat(count)),nudge_y = 5)+\n  geom_text(stat = 'count',aes(label = scales::percent(after_stat(count/sum(count)))), nudge_y = 15)+\n  geom_bar() +\n  labs(y = \"No. of Pupils\",x = \"Race\") +\n  theme(axis.title.y = element_text(hjust = 1)) \n\n\n\n\n\nggplot(data = exam_data,\n       aes(x=MATHS))+\n  geom_histogram(bins = 20,\n                 color = \"black\",\n                 fill = \"light blue\") +\n  geom_vline(xintercept = mean(exam_data$MATHS),\n             color = \"red\",\n             linetype = \"longdash\") +\n  geom_vline(xintercept = median(exam_data$MATHS),\n             color = \"black\",\n             linetype = \"longdash\")\n\n\n\n\nReference: https://drsimonj.svbtle.com/plotting-background-data-for-groups-with-ggplot2\n\nexam_without_gender = exam_data[,-3]\nggplot(data=exam_data,\n       aes(x = ENGLISH, fill = GENDER)) +\n  geom_histogram(data = exam_without_gender,fill = \"grey\",binwidth = 2.5,alpha = 0.5) +\n  geom_histogram(binwidth = 2.5,color = \"black\") +\n  facet_wrap(~GENDER) +\n  ylim(0,30)+\n  guides(fill = FALSE) #remove legend\n\nWarning: The `<scale>` argument of `guides()` cannot be `FALSE`. Use \"none\" instead as\nof ggplot2 3.3.4.\n\n\n\n\n\n\nggplot(data=exam_data,\n       aes(x = MATHS,y=ENGLISH)) +\n  geom_point()+\n  xlim(0,100)+\n  ylim(0,100)+\n  geom_vline(xintercept = 50,linetype = \"longdash\") +\n  geom_hline(yintercept = 50, linetype = \"longdash\")"
  },
  {
    "objectID": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "href": "Hands-on_Ex/Hands-on_Ex02/Hands-on_Ex02.html",
    "title": "Hands on Ex 2: Create Elegant Graphs using ggplot2",
    "section": "",
    "text": "Load Packages\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "href": "In-class_Ex/In-class_Ex03/In-class_Ex03.html",
    "title": "In-class Exercise 3",
    "section": "",
    "text": "Two packages will be installed and loaded. They are tidyverse and ggiraph.\n\n#always load the tidyverse lastly\npacman::p_load(ggiraph,tidyverse)\n\nImport data\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\n\n\n\n\nplot1 <- ggplot(data = exam,\n                aes(x = MATHS)) +\n  geom_dotplot(dotsize=0.5) +\n  ggtitle(\"Distribution of Maths Scores\")\nplot1\n\n\n\n\nCreate interactive dotplot\n\nplot2 <- ggplot(data = exam,\n                aes(x=MATHS)) +\n  #create interactivity\n  geom_dotplot_interactive(\n    aes(tooltip = ID),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  \n  scale_y_continuous(NULL,breaks = NULL)\n                     \n# create widget for interactivity\n# need to pass over the ggplot object to girafe\ngirafe(\n  ggobj = plot2, \n  #Create space\n  width_svg = 6,\n  height_svg = 6 *0.618\n)\n\n\n\n\n\nDisplay more than one in tooltips\n\nexam$tooltip <- c(paste0(\n  \"Name = \", exam$ID,\n  \"\\n Class = \", exam$CLASS\n))\n\nplot3 <- ggplot(data = exam,\n                aes(x=MATHS)) +\n  #create interactivity\n  geom_dotplot_interactive(\n    aes(tooltip = exam$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  \n  scale_y_continuous(NULL,breaks = NULL)\n                     \n# create widget for interactivity\n# need to pass over the ggplot object to girafe\ngirafe(\n  ggobj = plot3, \n  #Create space\n  width_svg = 6,\n  height_svg = 6 *0.618,\n  \n    )\n\n\n\n\n\nCusomise tooltip\n\ntooltip_css <- \"background-color:white;\nfont-style:bold;color:black;\"\n\n\n\n\nexam$tooltip <- c(paste0(\n  \"Name = \", exam$ID,\n  \"\\n Class = \", exam$CLASS\n))\n\nplot3 <- ggplot(data = exam,\n                aes(x=MATHS)) +\n  #create interactivity\n  geom_dotplot_interactive(\n    aes(tooltip = exam$tooltip),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\") +\n  \n  scale_y_continuous(NULL,breaks = NULL)\n                     \n# create widget for interactivity\n# need to pass over the ggplot object to girafe\ngirafe(\n  ggobj = plot3, \n  #Create space\n  width_svg = 6,\n  height_svg = 6 *0.618,\n  options = list(\n    opts_tooltip(\n      css = tooltip_css\n    )\n  )\n)\n\n\n\n\n\ndisplay statistics <- check {function}\n\ntooltip <- function(y,ymax,accuracy = 0.01) {\n  mean <- scale :: number(y,accuracy = accuracy)\n  sem <- sacle\n  \n  \n}\n\n\n\n\nplot5 <- ggplot(data = exam,\n            aes (x = MATHS)) +\n  geom_dotplot_interactive(\n    aes(data_id = CLASS),\n    stackgroups = TRUE,\n    binwidth = 1,\n    method = \"histodot\"\n    \n  ) +\n  \n  scale_y_continuous(NULL, breaks = NULL)\n\n\ngirafe(\n  ggobj = plot5, \n  #Create space\n  width_svg = 6,\n  height_svg = 6 *0.618)\n\n\n\n\n\nchange hover effect\ncombine hover+tooltip"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "href": "In-class_Ex/In-class_Ex04/In-class_Ex04.html",
    "title": "In-class Exercise 4",
    "section": "",
    "text": "pacman::p_load(plotly,DT,patchwork,ggstatsplot,tidyverse)\n\n\nexam_data = read_csv(\"data/Exam_data.csv\")\n\n\nplot_ly(data = exam_data,\n        x = ~ENGLISH,\n        y=~MATHS,\n        color = ~RACE)\n\n\n\n\n\n\np <-ggplot(data = exam_data,\n           aes(x = MATHS,\n               y = ENGLISH)) +\n  geom_point(dotsize = 1) +\n  coord_cartesian(xlim=c(0,100),\n                  ylim=c(0,100))\nggplotly(p)\n\n\n\n\n\n\nggbetweenstats(\n  data = exam_data,\n  x =  GENDER,\n  y = MATHS,\n  tpye = \"p\",\n  messages = FALSE\n  \n  \n)\n\n\n\n# student-t test: assume equal var.\n\n\nggscatterstats(\n  data = exam_data,\n  x = MATHS,\n  y = ENGLISH,\n  marginal = TRUE\n)\n\n\n\n\n#Model\n\n# last three comes from easystats: https://easystats.github.io/easystats/\n# readxl belongs to tidyverse but not in default install list\npacman::p_load(readxl,performance,pparameters,see,gtsummary)\n\n\ncar_resale <-read_xls(\"data/ToyotaCorolla.xls\",\n                      \"data\")\ncar_resale\n\n# A tibble: 1,436 × 38\n      Id Model       Price Age_0…¹ Mfg_M…² Mfg_Y…³     KM Quart…⁴ Weight Guara…⁵\n   <dbl> <chr>       <dbl>   <dbl>   <dbl>   <dbl>  <dbl>   <dbl>  <dbl>   <dbl>\n 1    81 TOYOTA Cor… 18950      25       8    2002  20019     100   1180       3\n 2     1 TOYOTA Cor… 13500      23      10    2002  46986     210   1165       3\n 3     2 TOYOTA Cor… 13750      23      10    2002  72937     210   1165       3\n 4     3  TOYOTA Co… 13950      24       9    2002  41711     210   1165       3\n 5     4 TOYOTA Cor… 14950      26       7    2002  48000     210   1165       3\n 6     5 TOYOTA Cor… 13750      30       3    2002  38500     210   1170       3\n 7     6 TOYOTA Cor… 12950      32       1    2002  61000     210   1170       3\n 8     7  TOYOTA Co… 16900      27       6    2002  94612     210   1245       3\n 9     8 TOYOTA Cor… 18600      30       3    2002  75889     210   1245       3\n10    44 TOYOTA Cor… 16950      27       6    2002 110404     234   1255       3\n# … with 1,426 more rows, 28 more variables: HP_Bin <chr>, CC_bin <chr>,\n#   Doors <dbl>, Gears <dbl>, Cylinders <dbl>, Fuel_Type <chr>, Color <chr>,\n#   Met_Color <dbl>, Automatic <dbl>, Mfr_Guarantee <dbl>,\n#   BOVAG_Guarantee <dbl>, ABS <dbl>, Airbag_1 <dbl>, Airbag_2 <dbl>,\n#   Airco <dbl>, Automatic_airco <dbl>, Boardcomputer <dbl>, CD_Player <dbl>,\n#   Central_Lock <dbl>, Powered_Windows <dbl>, Power_Steering <dbl>,\n#   Radio <dbl>, Mistlamps <dbl>, Sport_Model <dbl>, Backseat_Divider <dbl>, …\n\n\n\nmodel <- lm(Price ~Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period,\n            data = car_resale)\n\nmodel\n\n\nCall:\nlm(formula = Price ~ Age_08_04 + Mfg_Year + KM + Weight + Guarantee_Period, \n    data = car_resale)\n\nCoefficients:\n     (Intercept)         Age_08_04          Mfg_Year                KM  \n      -2.637e+06        -1.409e+01         1.315e+03        -2.323e-02  \n          Weight  Guarantee_Period  \n       1.903e+01         2.770e+01  \n\n\nThe coefficients, predicted values etc can be save as data tables for future/easier comparisons and generate the reports. check gtsummary.\n\ntbl_regression(model)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    Age_08_04\n-14\n-35, 7.1\n0.2\n    Mfg_Year\n1,315\n1,059, 1,571\n<0.001\n    KM\n-0.02\n-0.03, -0.02\n<0.001\n    Weight\n19\n17, 21\n<0.001\n    Guarantee_Period\n28\n3.8, 52\n0.023\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\nDiagnostic Check\n\ncheck_collinearity(model)\n\n# Check for Multicollinearity\n\nLow Correlation\n\n             Term   VIF     VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n Guarantee_Period  1.04   [1.01, 1.17]         1.02      0.97     [0.86, 0.99]\n        Age_08_04 31.07 [28.08, 34.38]         5.57      0.03     [0.03, 0.04]\n         Mfg_Year 31.16 [28.16, 34.48]         5.58      0.03     [0.03, 0.04]\n\nHigh Correlation\n\n   Term  VIF   VIF 95% CI Increased SE Tolerance Tolerance 95% CI\n     KM 1.46 [1.37, 1.57]         1.21      0.68     [0.64, 0.73]\n Weight 1.41 [1.32, 1.51]         1.19      0.71     [0.66, 0.76]\n\n\nWith performace from easystsats, we can visual the diagnostic check.\n\ncheck_c <- check_collinearity((model))\nplot(check_c)\n\n\n\n\n\ncheck_model(model)\n\n\n\n\nremove one the two highly correlated vars.\n\nmodel1 <- lm(Price ~Age_08_04 + KM + Weight + Guarantee_Period,\n            data = car_resale)\n\ntbl_regression(model1,intercept = TRUE)\n\n\n\n\n\n  \n  \n    \n      Characteristic\n      Beta\n      95% CI1\n      p-value\n    \n  \n  \n    (Intercept)\n-2,186\n-4,093, -278\n0.025\n    Age_08_04\n-119\n-125, -114\n<0.001\n    KM\n-0.02\n-0.03, -0.02\n<0.001\n    Weight\n20\n18, 21\n<0.001\n    Guarantee_Period\n27\n2.1, 52\n0.034\n  \n  \n  \n    \n      1 CI = Confidence Interval\n    \n  \n\n\n\n\n\ncheck_n <- check_normality(model1)\nplot(check_n)\n\n\n\n\n\nplot(compare_performance(model,model1),rank = TRUE)\n\n\n\n\n#Visusliase Uncertainty ### Use ggplot2\n\nmy_sum = exam_data %>%\n  group_by(RACE) %>%\n  summarise(\n    n = n(),\n    mean = mean(MATHS),\n    sd = sd(MATHS)\n    \n    \n  )%>%\n  mutate(se=sd/sqrt(n-1))\n\n\nggplot(my_sum) +\n  geom_errorbar(\n    aes(x=RACE, \n        ymin=mean-se, \n        ymax=mean+se), \n    width=0.2, \n    colour=\"black\", \n    alpha=0.9, \n    size=0.5) +\n  geom_point(\n    aes(x=RACE,y=mean),\n    stat=\"identity\", #readin the single record\n    color = \"red\",\n    dotsize = 1.5,\n    alpha = 1\n  )\n\n\n\n\n\nUse ggdist method"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html",
    "title": "In-class Exercise 5 (Multivariate Analysis)",
    "section": "",
    "text": "Load packages\n\npacman::p_load(corrplot,tidyverse,ggstatsplot,GGally)\n\nRead Data\n\nwine <- read_csv(\"data/wine_quality.csv\")\n\nRows: 6497 Columns: 13\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (1): type\ndbl (12): fixed acidity, volatile acidity, citric acid, residual sugar, chlo...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\n\n\n\n\nggstatsplot::ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  ggcorrplot.args = list(hc.order = TRUE), # reorder according the hierarchical clustering\n  title = \"Correlogram for wine dataset\",\n  subtitle = \"Four pairs are no significant at p < 0.05\"\n)\n\n\n\n\n\n\n\nprovide USERs chances to choose paramaters when building shiny app\n\nggstatsplot::grouped_ggcorrmat(\n  data = wine,\n  cor.vars = 1:11,\n  grouping.var = type,\n  type = \"robust\",\n  p.adjust.method = \"holm\",\n  plotgrid.args = list(ncol = 2),\n  ggcorrplot.args = list(outline.color = \"black\", \n                         hc.order = TRUE,\n                         tl.cex = 10),\n  annotation.args = list(\n    tag_levels = \"a\",\n    title = \"Correlogram for wine dataset\",\n    subtitle = \"The measures are: alcohol, sulphates, fixed acidity, citric acid, chlorides, residual sugar, density, free sulfur dioxide and volatile acidity\",\n    caption = \"Dataset: UCI Machine Learning Repository\"\n  )\n)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#method-3-ggpairs",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#method-3-ggpairs",
    "title": "In-class Exercise 5 (Multivariate Analysis)",
    "section": "Method 3: ggpairs()",
    "text": "Method 3: ggpairs()\nNoticed that we only study the correlation relationship between all the continuous data. What if there is categorical and continuous data and u would like to plot everything at one glance?\nIn the generalised pairs plot: categorical vs categorical: bar categorical vs continuous: boxplot continuous vs continuous: scatterplot\n\nexam <- read_csv(\"data/Exam_data.csv\")\n\nRows: 322 Columns: 7\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (4): ID, CLASS, GENDER, RACE\ndbl (3): ENGLISH, MATHS, SCIENCE\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\nggpairs(data = exam, columns = 4:6)\n\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`.\n`stat_bin()` using `bins = 30`. Pick better value with `binwidth`."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#method-4-ternary-plot-using-ggtern-to-study-the-relationship-between-3-variables",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#method-4-ternary-plot-using-ggtern-to-study-the-relationship-between-3-variables",
    "title": "In-class Exercise 5 (Multivariate Analysis)",
    "section": "Method 4: Ternary Plot using ggtern to study the relationship between 3 variables",
    "text": "Method 4: Ternary Plot using ggtern to study the relationship between 3 variables\n\npop_data = read_csv(\"data/respopagsex2000to2018_tidy.csv\")\n\nRows: 108126 Columns: 5\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr (3): PA, SZ, AG\ndbl (2): Year, Population\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\npacman::p_load(ggtern,plotly)\n\nCreate three new age groups young, economic-active and old.\n\nagpop_mutated <- pop_data %>%\n  mutate(`Year` = as.character(Year))%>%\n  spread(AG,Population) %>% # transform the table using pivot wider\n  mutate(YOUNG = rowSums(.[4:8]))%>%\n  mutate(ACTIVE = rowSums(.[9:16]))  %>%\n  mutate(OLD = rowSums(.[17:21])) %>%\n  mutate(TOTAL = rowSums(.[22:24])) %>%\n  filter(Year == 2018)%>%\n  filter(TOTAL > 0) #no record of the total pop is 0.\n\n\nggtern(data=agpop_mutated, aes(x=YOUNG,y=ACTIVE, z=OLD)) +\n  geom_point() +\n  labs(title=\"Population structure, 2018\") +\n  theme_rgbw()\n\n\n\n\nMake improvements to make the above diagram interactive. In this example, since ggtern is an extension of ggplot2, we could not use ggplotly directly.\n\nlabel <- function(txt) {\n  list(\n    text = txt, \n    x = 0.1, y = 1,\n    ax = 0, ay = 0,\n    xref = \"paper\", yref = \"paper\", \n    align = \"center\",\n    font = list(family = \"serif\", size = 15, color = \"white\"),\n    bgcolor = \"#b3b3b3\", bordercolor = \"black\", borderwidth = 2\n  )\n}\n\naxis <- function(txt) {\n  list(\n    title = txt, tickformat = \".0%\", tickfont = list(size = 10)\n  )\n}\n\nternaryAxes <- list(\n  aaxis = axis(\"Young\"), \n  baxis = axis(\"Active\"), \n  caxis = axis(\"Old\")\n)\n\nplot_ly(\n  agpop_mutated, \n  a = ~YOUNG, \n  b = ~ACTIVE, \n  c = ~OLD, \n  color = I(\"black\"), \n  type = \"scatterternary\"\n) %>%\n  layout(\n    annotations = label(\"Ternary Markers\"), \n    ternary = ternaryAxes\n  )\n\nNo scatterternary mode specifed:\n  Setting the mode to markers\n  Read more about this attribute -> https://plotly.com/r/reference/#scatter-mode\n\n\n\n\n\n\nWhat if there is more than 3 variables? ## Method 5: heatmap (cell based) columns: variables rows: observations\n\npacman::p_load(seriation, dendextend, heatmaply)\nwh <- read_csv(\"data/WHData-2018.csv\")\n\nRows: 156 Columns: 12\n── Column specification ────────────────────────────────────────────────────────\nDelimiter: \",\"\nchr  (2): Country, Region\ndbl (10): Happiness score, Whisker-high, Whisker-low, Dystopia, GDP per capi...\n\nℹ Use `spec()` to retrieve the full column specification for this data.\nℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.\n\n\n\nrow.names(wh) <- wh$Country  #to rename the rows (change object ID) hence heatmaply will use it to label the axis later\n\nWarning: Setting row names on a tibble is deprecated.\n\nwh1 <- dplyr::select(wh, c(3, 7:12))\nwh_matrix <- data.matrix(wh)\n\nInteractive heatmaply (supported by shiny)\n\nheatmaply(percentize(wh_matrix[, -c(1, 2, 4, 5)]))"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#method-6-kmean-clustering-using-parallel-coordinate",
    "href": "In-class_Ex/In-class_Ex05/In-class_Ex05.html#method-6-kmean-clustering-using-parallel-coordinate",
    "title": "In-class Exercise 5 (Multivariate Analysis)",
    "section": "Method 6: kmean clustering using parallel coordinate",
    "text": "Method 6: kmean clustering using parallel coordinate\nstatic: ggparcoord() interactive: parallellplot using ds3.jt\n\npacman::p_load(parallelPlot)\n\n\nhistoVisibility <- rep(TRUE, ncol(wh))\nparallelPlot(wh,\n             rotateTitle = TRUE,\n             histoVisibility = histoVisibility)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/Hands-on_Ex06-VisTime.html",
    "href": "In-class_Ex/In-class_Ex06/Hands-on_Ex06-VisTime.html",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "",
    "text": "By the end of this hands-on exercise you will be able create the followings data visualisation by using R packages:\n\nplotting a calender heatmap by using ggplot2 functions,\nplotting a cycle plot by using ggplot2 function,\nplotting a horizon chart"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/Hands-on_Ex06-VisTime.html#getting-started",
    "href": "In-class_Ex/In-class_Ex06/Hands-on_Ex06-VisTime.html#getting-started",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Getting Started",
    "text": "Getting Started\n::: callout-info ## Do It Yourself Write a code chunk to check, install and launch the following R packages: scales, viridis, lubridate, ggthemes, gridExtra, readxl, knitr, data.table and tidyverse.\n\n\nShow the code\npacman::p_load(scales, viridis, lubridate, ggthemes, gridExtra, tidyverse, readxl, knitr, data.table)"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "href": "In-class_Ex/In-class_Ex06/Hands-on_Ex06-VisTime.html#plotting-calendar-heatmap",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Plotting Calendar Heatmap",
    "text": "Plotting Calendar Heatmap\nIn this section, you will learn how to plot a calender heatmap programmetically by using ggplot2 package.\n\nBy the end of this section, you will be able to:\n\nplot a calender heatmap by using ggplot2 functions and extension,\nto write function using R programming,\nto derive specific date and time related field by using base R and lubridate packages\nto perform data preparation task by using tidyr and dplyr packages.\n\n\nThe Data\nFor the purpose of this hands-on exercise, eventlog.csv file will be used. This data file consists of 199,999 rows of time-series cyber attack records by country.\n\n\nImporting the data\nFirst, you will use the code chunk below to import eventlog.csv file into R environment and called the data frame as attacks.\n\nattacks <- read_csv(\"data/eventlog.csv\")\n\n\n\nExamining the data structure\nIt is always a good practice to examine the imported data frame before further analysis is performed.\nFor example, kable() can be used to review the structure of the imported data frame.\n\nkable(head(attacks))\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\nThere are three columns, namely timestamp, source_country and tz.\n\ntimestamp field stores date-time values in POSIXct format.\nsource_country field stores the source of the attack. It is in ISO 3166-1 alpha-2 country code.\n\ntz field stores time zone of the source IP address.\n\n\n\n\n\n\ntimestamp\nsource_country\ntz\n\n\n\n\n2015-03-12 15:59:16\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:00:48\nFR\nEurope/Paris\n\n\n2015-03-12 16:02:26\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:02:38\nUS\nAmerica/Chicago\n\n\n2015-03-12 16:03:22\nCN\nAsia/Shanghai\n\n\n2015-03-12 16:03:45\nCN\nAsia/Shanghai\n\n\n\n\n\n\n\nData Preparation\nStep 1: Deriving weekday and hour of day fields\nBefore we can plot the calender heatmap, two new fields namely wkday and hour need to be derived. In this step, we will write a function to perform the task.\n\nmake_hr_wkday <- function(ts, sc, tz) {\n  real_times <- ymd_hms(ts, \n                        tz = tz[1], \n                        quiet = TRUE)\n  dt <- data.table(source_country = sc,\n                   wkday = weekdays(real_times),\n                   hour = hour(real_times))\n  return(dt)\n  }\n\nNote: ymd_hms() and hour() are from lubridate package and weekdays() is a base R function.\nStep 2: Deriving the attacks tibble data frame\n\nwkday_levels <- c('Saturday', 'Friday', \n                  'Thursday', 'Wednesday', \n                  'Tuesday', 'Monday', \n                  'Sunday')\n\nattacks <- attacks %>%\n  group_by(tz) %>%\n  do(make_hr_wkday(.$timestamp, \n                   .$source_country, \n                   .$tz)) %>% \n  ungroup() %>% \n  mutate(wkday = factor(\n    wkday, levels = wkday_levels),\n    hour  = factor(\n      hour, levels = 0:23))\n\nNote: Beside extracting the necessary data into attacks data frame, mutate() of dplyr package is used to convert wkday and hour fields into factor so they’ll be ordered when plotting\nTable below shows the tidy tibble table after processing.\n\nkable(head(attacks))\n\n\n\n\ntz\nsource_country\nwkday\nhour\n\n\n\n\nAfrica/Cairo\nBG\nSaturday\n20\n\n\nAfrica/Cairo\nTW\nSunday\n6\n\n\nAfrica/Cairo\nTW\nSunday\n8\n\n\nAfrica/Cairo\nCN\nSunday\n11\n\n\nAfrica/Cairo\nUS\nSunday\n15\n\n\nAfrica/Cairo\nCA\nMonday\n11\n\n\n\n\n\n\n\nBuilding the Calendar Heatmaps\n\ngrouped <- attacks %>% \n  count(wkday, hour) %>% \n  ungroup() %>%\n  na.omit()\n\nggplot(grouped, \n       aes(hour, \n           wkday, \n           fill = n)) + \ngeom_tile(color = \"white\", \n          size = 0.1) + \ntheme_tufte(base_family = \"Helvetica\") + \ncoord_equal() +\nscale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\nlabs(x = NULL, \n     y = NULL, \n     title = \"Attacks by weekday and time of day\") +\ntheme(axis.ticks = element_blank(),\n      plot.title = element_text(hjust = 0.5),\n      legend.title = element_text(size = 8),\n      legend.text = element_text(size = 6) )\n\n\n\n\nThings to learn from the code chunk: - a tibble data table called grouped is derived by aggregating the attack by wkday and hour fields. - a new field called n is derived by using group_by() and count() functions. - na.omit() is used to exclude missing value. - geom_tile() is used to plot tiles (grids) at each x and y position. color and size arguments are used to specify the border color and line size of the tiles. - theme_tufte() of ggthemes package is used to remove unnecessary chart junk. To learn which visual components of default ggplot2 have been excluded, you are encouraged to comment out this line to examine the default plot. - coord_equal() is used to ensure the plot will have an aspect ratio of 1:1. - scale_fill_gradient() function is used to creates a two colour gradient (low-high).\n\n\n\n\n\nThen we can simply group the count by hour and wkday and plot it, since we know that we have values for every combination there’s no need to further preprocess the data.\n\n\nBuilding Multiple Calendar Heatmaps\nChallenge: Building multiple heatmaps for the top four countries with the highest number of attacks.\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 1: Deriving attack by country object\nIn order to identify the top 4 countries with the highest number of attacks, you are required to do the followings:\n\ncount the number of attacks by country,\ncalculate the percent of attackes by country, and\nsave the results in a tibble data frame.\n\n\nattacks_by_country <- count(\n  attacks, source_country) %>%\n  mutate(percent = percent(n/sum(n))) %>%\n  arrange(desc(n))\n\nStep 2: Preparing the tidy data frame\nIn this step, you are required to extract the attack records of the top 4 countries from attacks data frame and save the data in a new tibble data frame (i.e. top4_attacks).\n\ntop4 <- attacks_by_country$source_country[1:4]\ntop4_attacks <- attacks %>%\n  filter(source_country %in% top4) %>%\n  count(source_country, wkday, hour) %>%\n  ungroup() %>%\n  mutate(source_country = factor(\n    source_country, levels = top4)) %>%\n  na.omit()\n\n\n\nPlotting Multiple Calendar Heatmaps\nStep 3: Plotting the Multiple Calender Heatmap by using ggplot2 package.\n\nggplot(top4_attacks, \n       aes(hour, \n           wkday, \n           fill = n)) + \n  geom_tile(color = \"white\", \n          size = 0.1) + \n  theme_tufte(base_family = \"Helvetica\") + \n  coord_equal() +\n  scale_fill_gradient(name = \"# of attacks\",\n                    low = \"sky blue\", \n                    high = \"dark blue\") +\n  facet_wrap(~source_country, ncol = 2) +\n  labs(x = NULL, y = NULL, \n     title = \"Attacks on top 4 countries by weekday and time of day\") +\n  theme(axis.ticks = element_blank(),\n        axis.text.x = element_text(size = 7),\n        plot.title = element_text(hjust = 0.5),\n        legend.title = element_text(size = 8),\n        legend.text = element_text(size = 6) )"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/Hands-on_Ex06-VisTime.html#cycle-plot",
    "href": "In-class_Ex/In-class_Ex06/Hands-on_Ex06-VisTime.html#cycle-plot",
    "title": "Hands-on Exercise 6: Visualising and Analysing Time-oriented Data",
    "section": "Cycle Plot",
    "text": "Cycle Plot\nIn this section, you will learn how to plot a cycle plot showing the time-series patterns and trend of visitor arrivals from Vietnam programmatically by using ggplot2 functions.\n\n\nData Preparation\n\nStep 1: Data Import\nFor the purpose of this hands-on exercise, arrivals_by_air.xlsx will be used.\nThe code chunk below imports arrivals_by_air.xlsx by using read_excel() of readxl package and save it as a tibble data frame called air.\n\nair <- read_excel(\"data/arrivals_by_air.xlsx\")\n\n\n\nStep 2: Deriving month and year fields\nNext, two new fields called month and year are derived from Month-Year field.\n\nair$month <- factor(month(air$`Month-Year`), \n                    levels=1:12, \n                    labels=month.abb, \n                    ordered=TRUE) \nair$year <- year(ymd(air$`Month-Year`))\n\n\n\nStep 4: Extracting the target country\nNext, the code chunk below is use to extract data for the target country (i.e. Vietnam)\n\nVietnam <- air %>% \n  select(`Vietnam`, \n         month, \n         year) %>%\n  filter(year >= 2010)\n\n\n\nStep 5: Computing year average arrivals by month\nThe code chunk below uses group_by() and summarise() of dplyr to compute year average arrivals by month.\n\nhline.data <- Vietnam %>% \n  group_by(month) %>%\n  summarise(avgvalue = mean(`Vietnam`))\n\n\n\n\nPlotting the cycle plot\nThe code chunk below is used to plot the cycle plot as shown in Slide 12/23.\n\nggplot() + \n  geom_line(data=Vietnam,\n            aes(x=year, \n                y=`Vietnam`, \n                group=month), \n            colour=\"black\") +\n  geom_hline(aes(yintercept=avgvalue), \n             data=hline.data, \n             linetype=6, \n             colour=\"red\", \n             size=0.5) + \n  facet_grid(~month) +\n  labs(axis.text.x = element_blank(),\n       title = \"Visitor arrivals from Vietnam by air, Jan 2010-Dec 2019\") +\n  xlab(\"\") +\n  ylab(\"No. of Visitors\")"
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html",
    "title": "In Class Ex 06(Tableau for time series)",
    "section": "",
    "text": "arrival time series dataset could be downloaded here.\n\n\n\n\n\n\n\n\nstep\ndescription\nscreenshot\n\n\n\n\n0\nraw data\n\n\n\n1\npivot long\n\n\n\n2\nadd filters to plot the time series for each country for a specific range of time.\n\n\n\n3\nsplit the trend and the seasonal using cyclical plot(year of individual month)\nFindings: Italy August F1, drastic increase over the year in August in Italy\n\n\n\n4\nbuild a dashboard to gain a better understanding of the arrivals for each country.\nnote: synchronize the filter of country and time range for both worksheets.\n\n\n\n\nThe tableau dashboard can be access here."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#calender-heatmap-for-time-series",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#calender-heatmap-for-time-series",
    "title": "In Class Ex 06(Tableau for time series)",
    "section": "Calender Heatmap for time series",
    "text": "Calender Heatmap for time series\nThe tableau dashboard can be accessed here."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#slopegraphs-for-time-series",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#slopegraphs-for-time-series",
    "title": "In Class Ex 06(Tableau for time series)",
    "section": "Slopegraphs for time series",
    "text": "Slopegraphs for time series\nThe tableau dashboard can be accessed here."
  },
  {
    "objectID": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#animation-using-pages",
    "href": "In-class_Ex/In-class_Ex06/In-class_Ex06.html#animation-using-pages",
    "title": "In Class Ex 06(Tableau for time series)",
    "section": "Animation using pages",
    "text": "Animation using pages\nThe tableau dashboard can be accessed here."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ISSS-VAA",
    "section": "",
    "text": "Welcome to ISSS608 Visual Analytics and Applications homepage. In this website, you will find my coursework prepared for this course."
  },
  {
    "objectID": "Others/general case.html",
    "href": "Others/general case.html",
    "title": "general case",
    "section": "",
    "text": "Category\nFeature\nImpact\n\n\n\n\nHomepage\n\n\n\n\n\nNo Ads\nClean and nice layout improves the overall customer experience\nCustomer’s attention is not distracted\n\n\nFood Delivery\n\n\n\n\n\nPandabox\n\nattract customers to make purchase with limited time of offers\nincrease basket value\nattract customers to try new restaurants\n\n\n\n\nSpeed of Delivery\nshorter waiting time improves the overall customer experience\n\n\n\nProfessional Riders\nRiders will not leave food on the floor/hang it on the door handle when asked to leave the food at doorstep. Instead, they will place it on the empty space on the shoe rack.\n\n\nPick-up\n\n\n\n\n\ncredit card promotion\nattract customers to link credit card\n\n\n\npandapro enjoys extra discount\nattract customers to subscribe, as pick up price sometimes cheaper than purchase in store\n\n\nSubsription\n\n\n\n\n\nLowest subscription fee\nCustomers who is aware of the pick-up discount are more likely to join the membership"
  },
  {
    "objectID": "Others/general case.html#cons",
    "href": "Others/general case.html#cons",
    "title": "general case",
    "section": "Cons",
    "text": "Cons\n\n\n\n\n\n\n\n\nCategory\nFeature\nImpact\n\n\n\n\nFood Delivery\n\n\n\n\n\npandapro free delivery requirement not clearly stated\ncustomers might get disappointed\n\n\n\nchoices on Chinese cuisines\nnot as many as the competitor’s\n\n\n\nno mix&match\ncustomer choose not to place an order when they could not meet the minimum order amount from a single restaurant\n\n\n\nno variation on delivery fee\ncustomers who are willing to wait for longer time to pay lower delivery fee might choose to order from competitor’s app\n\n\nPanda Rewards\n\n\n\n\n\nthe points could not be earned automatically after placing orders\ncustomers who used to be awarded automatically might get disappointed"
  },
  {
    "objectID": "Others/pricing schemes.html",
    "href": "Others/pricing schemes.html",
    "title": "Pricing Schemes",
    "section": "",
    "text": "Design\n\nFlat: Delivery fee is fixed with a minimum order amount requirement.\nFor example, delivery = $2.99 with minimum order requirement $36.04.\nNote: The flat rate can be designed based on the geographical location. The rate is higher in CBD where customers have higher personal income.\nFlexible: Delivery fee is calculated using the formula max($0.99, $12 - OrderValue * 0.25), where the minimum order amount required is $28.04.\nTiered: Based on the order values. For example,\n\nif there are 2 categories:\n$0.99 for orders above $44.04\n$4.99 for orders below $44.04\nIf there are 3 categories:\n$0.99 for orders above $44.04\n$3.99 for orders above $32.04\n$4.99 for orders above $28.04\n\n\nAssumptions\n\naverage order value of $40 .\nthe new customers’ behavior follow the existing customers.\nthere is always a minimum order value requirement of 28.04 if not stated, as we do not want the delivery fee to eat into company’s revenue.\nassume that when we cluster customer into 3 clusters, the most representative customer in each cluster spends $28.04, $32.04 and $44.04.\nusually the delivery fee is distance-based. In the above settings, we assume that customer will always choose from the nearest pandamart vendor."
  },
  {
    "objectID": "Others/pricing schemes.html#b.-kpis-used-to-evaluate-the-pricing-schemes",
    "href": "Others/pricing schemes.html#b.-kpis-used-to-evaluate-the-pricing-schemes",
    "title": "Pricing Schemes",
    "section": "B. KPIs used to evaluate the pricing schemes",
    "text": "B. KPIs used to evaluate the pricing schemes\n\nFor different objectives, the KPIs are different. The objectives could be maximize revenue, convert the most number of new customer with the same revenue, maximize the number of orders with the same revenue, maximize the basket value with the same revenue and etc. One of the objective is chosen for this case study.\nGoal: Maximize the number of orders while keeping the target revenue per order at $12\nThat is, we need to determine the best delivery fee in order to achieve the revenue per order above $12 with more orders.\nKPIs\n\n\n\n\n\n\n\n\nCategory\nName\nObjective\n\n\n\n\nRevenue Leads\n\n\n\n\n\nDelivery Fee\nTo find how much do customers willing to pay for a delivery charge, and how does each pricing schemes affect the willingness of paying for delivery charge\n\n\n\nRevenue\nTo find if the new pricing scheme can generate more revenue\n\n\n\nNumber of orders\nTo find if the new pricing scheme can generate more orders from customers\n\n\n\nBasket value\nTo find if the new pricing scheme can increase the basket value for an order\n\n\nApp Engagement\n\n\n\n\n\ntime on page\nTo find if the different pricing schemes affect the customer’s time spent on each page, especially in the “cart” page.\n\n\n\nbounce rate\nTo find if different schemes of delivery fee affect the percentage of visitors that leave the pandamart page without taking any action\n\n\n\nclick through probability\nTo find the probability that a customer click/goes to next step, especially from cart to checkout, and from checkout to finish payment"
  },
  {
    "objectID": "Others/pricing schemes.html#c.-ab-test",
    "href": "Others/pricing schemes.html#c.-ab-test",
    "title": "Pricing Schemes",
    "section": "C. A/B Test",
    "text": "C. A/B Test\n\nThe customers are picked randomly (or we can consider geo-based randomization) and been assigned to control or treatment group. The customers in control group will use the current pricing scheme, while the customers in treatment group will see the new pricing scheme. To keep providing consistent shopping experience, we define customer using their customer_id.\nHypothesis\nThe null hypothesis is that there is no difference in each of the KPIs. The alternative hypothesis can be one-sided or two-sided test. For example, we need to decide whether the new pricing scheme is a better choice to meet the goal stated in part B.\nH0: There is no difference in number_of_orders.\nH1: There is a significant increase in number_of_orders.\nCalculate the sample size. Choose the significance level, power, minimum detectable difference. Once these inputs are finalized, we can use the formula to calculate the sample size.\nChoose the duration of ab test. We could consider days of week effect, seasonality, frequency of purchasing groceries etc. The duration could be set for at least one week.\nAnalyse the results. We should first check the randomisation of sampling by comparing the baseline metrics between two groups. Then we should conduct statistitical test. Statistically, we could use p-values only to tell whether to reject the null hypothesis. Practically, we could compare the confidence interval with the minimum detectable difference used in industry to decide whether its a better pricing scheme or not."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html",
    "title": "Take Home Exercise 01",
    "section": "",
    "text": "Age-sex pyramid is an analytical visualisation commonly used by demographers to reveal the structure of population by gender and age group. In this take-home exercise, you are required to reveal the demographic structure of Singapore at planning area level by using age-sex pyramid method. Instead of plotting a single age-sex pyramid, however, you are required to display nine selected planning areas on a single view by using trellis display (also know as small-multiple plot).\nSingapore Residents by Planning Area / Subzone, Age Group, Sex and Type of Dwelling, June 2022 should be used to prepare the analytical visualisation. The data can be downloaded here."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#use-tableau-prep-for-data-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#use-tableau-prep-for-data-preparation",
    "title": "Take Home Exercise 01",
    "section": "4.1 Use Tableau Prep for data preparation",
    "text": "4.1 Use Tableau Prep for data preparation\nThe flow of the data preparation to obtain the Median Age and Old Age Support Ratio for each PA is as shown below.\n\n\n\nFig 4.1.1 Tableau Prep Workflow\n\n\n\n\n\n\n\n\n\n\n\nNo.\nStep\nScreenshot\n\n\n\n\n1\nLoad the originl data csv into Tableau Prep by click the plus symbol besides Connections, then choose Text File.\n\n\n\n2\nHide unnecessary columns by unclick the specific Field Name. In this task, the SZ(subzone), FA(floor area), Time(2022) are hided.\n\n\n\n3\nCalculate median age for each age group, and the total age for each row = median age * population in each row.\n\n\n\n4\nAggregate the age and population for each PA.\n\n\n\n5\nCalculate the median age for each PA and output as csv file.\n\n\n\n6\nCreate new age group by grouping original age groups.\n\n\n\n7\nAggregate population for each PA.\n\n\n\n8\nConvert the long table to wide table.\n\n\n\n9\nCalculate old age support ratio for each PA and output as csv file."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#build-dashboard",
    "href": "Take-Home_Ex/Take-Home_Ex01/Take-Home_Ex01.html#build-dashboard",
    "title": "Take Home Exercise 01",
    "section": "4.2 Build Dashboard",
    "text": "4.2 Build Dashboard\n\n4.2.1 Draw Map Highlighting the 9 Most Populated PA in Singapore\n\n\n\n\n\n\n\n\n\nNo.\nStep\nScreenshot\n\n\n\n\n1\nLoad the original population .csv file, subzone by planning area .shp file and the two output files with derived measures (old age support ratio and median age) in each planning region .csv files in Tableau Desktop( for mapping purpose).\n\n\n\n2\nDrag all the files besides the original of population file to join files by matching PA (the name of the planning areas). Note that in .shp file, the name of planning areas are in upper case. We need to edit the matching by Upper(PA) = PA(.shp file).\n\n\n\n3\nFiles are joined successfully.\n\n\n\n4\nDrop Geometry to the field.\n\n\n\n5\nDrag Pop to Color, PA to Label.\n\n\n\n6\nEdit the color. When we choose step 3 and modify the color of least population to light grey, the no. of highlighted region is 9.\n\n\n\n7\nEdit the label on the map. Select always show for Punggol and Bedok, and never show for the rest PA. We can annotate the two highlighted regions to facilitate understanding.\n\n\n\n\n\n\n\n4.2.2 Draw Pyramids of the 9 PAs and Display in Trellis (single diagram)\n\n\n\n\n\n\n\n\n\nNo.\nStep\nScreenshot\n\n\n\n\n1\nManually sort the PA (name of planning areas) based on median age as we would like to control the arrangement of pyramids of PA in trellis.\n\n\n\n2\nThe 9 most populated PA are sorted, while the rest of PA are unchanged.\n\n\n\n3\nCreate a new parameter representing the number of columns in trellis. In this example, the parameter should be sqrt(9) = 3. Note that creating such parameter is to avoid hard code.\n\n\n\n4\nCreate a new calculated field named Index of each row.\n\n\n\n5\nCreate a new calculated field named Column Index of each row.\n\n\n\n6\nCreate a new calculated field named Row Index of each row. Note that the column index and row index will be used when we need to display the 9 pyramids in trellis (a single diagram containning many small plots). The two index serve the purpose as the coordinate of each small plot, such as (1,1) in the top left corner and (3,3) in the bottom right corner.\n\n\n\n7\nAs we would like to display partial data in trellis, we created a new calculated field called Group1 to group the 9 selected PA in one group,\n\n\n\n8\nThen we drop Group1, choose Attribute to filter and select ‘1’ only.\n\n\n\n9\nDue to space constrain, we create new age groups. In the original dataset, the step between consecutive age groups is 5. We increase it to 10. That is, we combine every 2 groups into 1, such as 0 to 4 and 5 to 9 into 0 to 9.\n\n\n\n\n10\nCreate new calculated field of population of males and females as shown.\n\n\n\n\n11\nDrop Row_Index, Male and Female into Columns.\nDrop Column_Index and AGE into Rows.\nDrop PA to Detail.\nNote that we need to modify the Row_Index and Column_Index by selecting computing using PA.\n\n\n\n12\nThen we drop the [Sex] to Colour, Rank of PA to Detail in Mark card of All. We can modify the color of sex by using blue to represent Male and Pink to represent Female.\n\n\n\n13\nModify the tooltip.\n\n\n\n14\nRearrange the order of age group on y axis.\n\n\n\n15\nAdd the label for the bar representing age group of 90+ for Males in each PA.\nFirst, select all bars and choose Mark Label -> Never Show.\nThen select the bars representing age group of 90+ and choose Mark Label -> Always Show.\n\n\n\n\n16\nThen add names of PA and median age of PA to Labels.\n\n\n\n17\nReverse the Male axis to build pyramid.\n\n\n\n\n18\nFormat of label by click the ‘…’ as shown on the screenshot.\nPlease note that in order for the label to appear on the top left corner, I specifically add a full stop of blue color after many empty spaces in the second line.\n\n\n\n19\nAdd the title of the worksheet.\nRemove the unnecessary headers to obtain the final view of the worksheet.\n\n\n\n20\nCreate a new worksheet to plot the pyramid of Singapore as a reference.\n\n\n\n21\nCreate a table showing the Old Age Support Ratio of each PA.\n\n\n\n22\nCreate a new dashboard and drop the worksheets to specific locations and adjust the width and height of each region.\nAdd Note, data source and update date.\n\n\n\n23\nPublish the dashboard. Note that we need to choose to Extract Data, instead of using Live Data.\n\n\n\n\n\nI appreciate you taking the time to read this article and paying attention to it."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html",
    "title": "Take Home Exercise 02",
    "section": "",
    "text": "The Task In this take-home exercise, you are required to:\n\nselect one of the Take-home Exercise 1 prepared by your classmate,\ncritic the submission in terms of clarity and aesthetics,\nprepare a sketch for the alternative design by using the data visualisation design principles and best practices, and\nremake the original design by using ggplot2, ggplot2 extensions and tidyverse packages."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#clarity",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#clarity",
    "title": "Take Home Exercise 02",
    "section": "Clarity",
    "text": "Clarity\n\nThe title of dashboard is unclear. We are suppose to represent the distribution of a population by age and sex, but not ‘age pyramid: sex pattern’.\nThe number of Planning Areas (PA) should be 9, but not all.\nThere is no annotation, subtitles or note to tell data story. Central tendency measures such as median could be added to provide audience with better interpretation of the distribution.\nIn a population pyramid, males are usually shown on the left by blue and females are usually shown on the right by pink/red. In the diagram, the different gender are represented by the same color.\nThe label of the y-axis of age is misleading. The age group should be represented by an interval (0 to 9, 10 to 19, 20 to 29, …) instead of an integer(0,10,20,…). The order of age group is wrong. And it should no start at null and end at 80. In fact, the ‘Null’ in the example should represent the group ‘90_and_above’.\nThe label of the x-axis is hard to read. In fact, the gender can be represented by legend and the ‘population’ can be labeled just once on x-axis.\nThere is no update date and data source.\n\n\nAesthetics\n\nThe arrangement of pyramids is only in the diagonal of a matrix. The information is not displayed in one page as many space are wasted. We should display the 9 pyramids in 3 * 3 matrix. It enables us to make comparisons quickly and easily."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#install-and-launching-r-packages",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#install-and-launching-r-packages",
    "title": "Take Home Exercise 02",
    "section": "Install and Launching R packages",
    "text": "Install and Launching R packages\nThe code chunk below uses p_load() of pacman package to check if tidyverse packages (ggplot2 belongs to tidyverse packages) are installed in the computer. If they are, then they will be launched into R.\n\npacman::p_load(tidyverse)"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#importing-the-data",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#importing-the-data",
    "title": "Take Home Exercise 02",
    "section": "Importing the data",
    "text": "Importing the data\n\npop_data <- read_csv(\"data/respopagesexfa2022.csv\")"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#data-preparation",
    "title": "Take Home Exercise 02",
    "section": "Data Preparation",
    "text": "Data Preparation\n\nDelete columns of “SZ”,“FA” and “Time” and keep “PA”, “AG”, “Sex” and “Pop”.\n\n\npop_data2 <- pop_data[,!names(pop_data) %in% c(\"SZ\",\"FA\",\"Time\")]\nhead(pop_data2,5)\n\n# A tibble: 5 × 4\n  PA         AG     Sex     Pop\n  <chr>      <chr>  <chr> <dbl>\n1 Ang Mo Kio 0_to_4 Males     0\n2 Ang Mo Kio 0_to_4 Males    10\n3 Ang Mo Kio 0_to_4 Males    20\n4 Ang Mo Kio 0_to_4 Males    60\n5 Ang Mo Kio 0_to_4 Males    10\n\n\n\nAdd the ranking number to the PA to find the 9 most populated PA.\n\n\npa_pop <- aggregate(Pop~PA,pop_data,sum)\n#pa_pop\npa_pop$rank <- NA\npa_pop$rank[order(-pa_pop$Pop)] <- 1:nrow(pa_pop)\nnine_most_populated <- filter(pa_pop,rank<=9)\n#nine_most_populated\nchosen_PA <- nine_most_populated$PA\nchosen_PA\n\n[1] \"Bedok\"         \"Choa Chu Kang\" \"Hougang\"       \"Jurong West\"  \n[5] \"Punggol\"       \"Sengkang\"      \"Tampines\"      \"Woodlands\"    \n[9] \"Yishun\"       \n\n\n\nFind the estimated mean age in each PA\n\n\npop_data_mean <- \n  mutate(pop_data2,\n    # Create New Age groups\n    AGE = case_when(\n      AG == \"0_to_4\" ~ 2,\n      AG == \"5_to_9\" ~ 7,\n      AG == \"10_to_14\" ~ 12,\n      AG == \"15_to_19\" ~ 17,\n      AG == \"20_to_24\" ~ 22,\n      AG == \"25_to_29\" ~ 27,     \n      AG == \"30_to_34\" ~ 32,\n      AG == \"35_to_39\" ~ 37,      \n      AG == \"40_to_44\" ~ 42,\n      AG == \"45_to_49\" ~ 47,     \n      AG == \"50_to_54\" ~ 52,\n      AG == \"55_to_59\" ~ 57, \n      AG == \"60_to_64\" ~ 62,\n      AG == \"65_to_69\" ~ 67,     \n      AG == \"70_to_74\" ~ 72,\n      AG == \"75_to_79\" ~ 77,      \n      AG == \"80_to_84\" ~ 82,\n      AG == \"85_to_89\" ~ 87,     \n      AG == \"90_and_over\" ~ 92\n      )\n    )\n\n# Find the total age for population in each age group\npop_data_mean <- pop_data_mean %>% \n  mutate(\n    Total_age_pa = ifelse(Pop == \"Null\", 0, AGE * Pop)\n  )\nhead(pop_data_mean,5)\n\n# A tibble: 5 × 6\n  PA         AG     Sex     Pop   AGE Total_age_pa\n  <chr>      <chr>  <chr> <dbl> <dbl>        <dbl>\n1 Ang Mo Kio 0_to_4 Males     0     2            0\n2 Ang Mo Kio 0_to_4 Males    10     2           20\n3 Ang Mo Kio 0_to_4 Males    20     2           40\n4 Ang Mo Kio 0_to_4 Males    60     2          120\n5 Ang Mo Kio 0_to_4 Males    10     2           20\n\n\n\n# Calculated the mean age of population in each PA\npa_mean <- aggregate(cbind(Pop,Total_age_pa)~PA,pop_data_mean,sum)\npa_mean <- pa_mean %>%\n  mutate(\n    mean_age_pa = Total_age_pa/Pop\n  )\n\n# Filter the dataset by showing the result of the 9 most populated PA\npa_mean <-pa_mean%>%\n  filter(PA %in% chosen_PA)\n# Arrange the PA by their mean age in descending order  \npa_mean <- pa_mean[order(pa_mean$mean_age_pa,decreasing=TRUE),]\npa_mean[c(1,4)]\n\n             PA mean_age_pa\n1         Bedok    43.81877\n3       Hougang    42.56407\n7      Tampines    41.13840\n4   Jurong West    40.39587\n9        Yishun    40.24887\n2 Choa Chu Kang    39.28368\n8     Woodlands    38.82079\n6      Sengkang    37.33709\n5       Punggol    34.78819"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#create-visualisation",
    "href": "Take-Home_Ex/Take-Home_Ex02/Take-Home_Ex02.html#create-visualisation",
    "title": "Take Home Exercise 02",
    "section": "Create Visualisation",
    "text": "Create Visualisation\n\nAggregate data using planning area and gender. Note that to build the age-sex pyramid, the male population should be equal to negative of the original value.\n\n\npop_data2$Population <- ifelse(pop_data2$Sex == \"Males\", (-1)*pop_data2$Pop,pop_data2$Pop)\nfinal_pop_data <- aggregate(Population~PA++AG+Sex,FUN = sum,data=pop_data2)\nmost_populatedPA_pop_data <- final_pop_data%>%filter(final_pop_data$PA %in% chosen_PA)\n\nhead(most_populatedPA_pop_data,5)\n\n             PA     AG     Sex Population\n1         Bedok 0_to_4 Females       4990\n2 Choa Chu Kang 0_to_4 Females       4090\n3       Hougang 0_to_4 Females       4460\n4   Jurong West 0_to_4 Females       4800\n5       Punggol 0_to_4 Females       6930\n\n\n\nDue to the space constain, we creat a new age group, AGE, where the range of each interval increases from 5 to 10.\n\n\nmost_populatedPA_pop_data <- most_populatedPA_pop_data %>%\n  mutate(\n    AGE = case_when(\n      AG == \"0_to_4\" | AG == \"5_to_9\" ~ \"0-9\",\n      AG == \"10_to_14\" | AG == \"15_to_19\" ~ \"10-19\",\n      AG == \"20_to_24\" | AG == \"25_to_29\" ~ \"20-29\",\n      AG == \"30_to_34\" | AG == \"35_to_39\" ~ \"30-39\",\n      AG == \"40_to_44\" | AG == \"45_to_49\" ~ \"40-49\",\n      AG == \"50_to_54\" | AG == \"55_to_59\" ~ \"50-59\",\n      AG == \"60_to_64\" | AG == \"65_to_69\" ~ \"60-69\",\n      AG == \"70_to_74\" | AG == \"75_to_79\" ~ \"70-79\",\n      AG == \"80_to_84\" | AG == \"85_to_89\" ~ \"80-89\",\n      AG == \"90_and_over\" ~ \">90\"\n    )\n  )\n  \nmost_populatedPA_pop_data <- aggregate(Population ~ PA + Sex + AGE, FUN = sum, data = most_populatedPA_pop_data)\n\nhead(most_populatedPA_pop_data,5)\n\n             PA     Sex AGE Population\n1         Bedok Females >90       1470\n2 Choa Chu Kang Females >90        450\n3       Hougang Females >90        880\n4   Jurong West Females >90        600\n5       Punggol Females >90        280\n\n\n\nJoin the two dataset: most_populatedPA_pop_data and pa_mean, i.e. add the mean age of each PA to the above table.\n\n\n#most_populatedPA_pop_data <- left_join(most_populatedPA_pop_data,pa_mean)\n#head(most_populatedPA_pop_data,5)\n\n\nVisualise the 9 age-sex pyramids in a 3 * 3 matrix.\n\n\nggplot(most_populatedPA_pop_data, \n       aes(x = AGE, y = Population, fill = Sex)) + \n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Females\"), stat = \"identity\") +\n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Males\"), stat = \"identity\") + \n  coord_flip()+\n  facet_wrap(~ PA,ncol = 3 ) +\n  labs(title=\"Age-sex Pyramids in 9 Most Populated PA, as of June 2022\", x = \"Age Group\",y=\"Population\") +\n  scale_y_continuous(breaks = seq(-20000, 20000, 10000), \n                     labels = paste0(as.character(c('20k','10k','0','10k','20k'))))\n\n\n\n\n\nWe notices that the order of the age group on y-axis is wrong. Hence, we need to reorder the age groups on y-axis as shown below. Moreover, the 9 most populated PA is arranged according to the mean age in descending order.\n\n\nmost_populatedPA_pop_data$AGE <- factor(most_populatedPA_pop_data$AGE,\n                                       levels = c(\"0-9\",\"10-19\",\"20-29\",\"30-39\",\"40-49\",\"50-59\",\"60-69\",\"70-79\",\"80-89\",\">90\"))\n\nmost_populatedPA_pop_data$PA <- factor(most_populatedPA_pop_data$PA,levels =\n                                         c(\"Bedok\",\"Hougang\",\"Tampines\",\"Jurong West\",\"Yishun\",\"Choa Chu Kang\", \"Woodlands\",\"Sengkang\",\"Punggol\"))\n\npyramids <- ggplot(most_populatedPA_pop_data, \n       aes(x = AGE, y = Population, fill = Sex)) + \n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Females\"), stat = \"identity\") +\n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Males\"), stat = \"identity\") + \n  coord_flip()+\n  facet_wrap(~ PA,ncol = 3 ) +\n  labs(title=\"Age-sex Pyramids in 9 Most Populated PA, as of June 2022\", x = \"Age Group\",y=\"Population\") +\n  scale_y_continuous(breaks = seq(-20000, 20000, 10000), \n                     labels = paste0(as.character(c('20k','10k','0','10k','20k'))))\npyramids\n\n\n\n\n\nThe above diagram can be improved by adding the mean age in each PA as labels.\n\n\nlabels <- c(\"Bedok\\nMean:43.8\",\"Hougang\\nMean:42.6\",\"Tampines\\nMean:41.3\",\n            \"Jurong West\\nMean:40.4\",\"Yishun\\nMean:40.2\",\"Choa Chu Kang\\nMean:39.3\",\n            \"Woodlands\\nMean:38.8\",\"Sengkang\\nMean:37.3\",\"Punggol\\nMean:34.8\")\nmost_populatedPA_pop_data$PA <- factor(most_populatedPA_pop_data$PA, labels = labels)\n\nvis <- ggplot(most_populatedPA_pop_data, \n       aes(x = AGE, y = Population, fill = Sex)) + \n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Females\"), stat = \"identity\") +\n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Males\"), stat = \"identity\") + \n  coord_flip()+\n  facet_wrap(~ PA,ncol = 3 ) +\n  labs(title=\"Age-sex Pyramids in 9 Most Populated PA, as of June 2022\", \n       subtitle = \"Bedok has the oldest age structure while Punggol has the youngest\",\n       x = \"Age Group\",y=\"Population\") +\n  scale_y_continuous(breaks = seq(-20000, 20000, 10000), \n                     labels = paste0(as.character(c('20k','10k','0','10k','20k')))) +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\",hjust = 0.5),\n    plot.subtitle = element_text(size = 10, color = \"darkgrey\",hjust = 0.5),\n    strip.text.x = element_text(size = 9),\n    axis.text=element_text(size=6)\n  )\nvis\n\n\n\n\n\nA nice improvement is to add the complete data set (Singapore) in the background of each pyramid.\n\n\nsg_pop_bg <- most_populatedPA_pop_data[,-1]\nggplot(most_populatedPA_pop_data, \n       aes(x = AGE, y = Population, fill = Sex)) + \n  geom_bar(data = subset(sg_pop_bg, Sex == \"Females\"), fill = \"grey\",stat = \"identity\") +\n  geom_bar(data = subset(sg_pop_bg, Sex == \"Males\"), fill = \"grey\",stat = \"identity\") + \n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Females\"), stat = \"identity\") +\n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Males\"), stat = \"identity\") + \n  coord_flip()+\n  facet_wrap(~ PA,ncol = 3 ) +\n  labs(title=\"Age-sex Pyramids in 9 Most Populated PA, as of June 2022\", \n       subtitle = \"Bedok has the oldest age structure while Punggol has the youngest\",\n       x = \"Age Group\",y=\"Population\") +\n  scale_y_continuous(breaks = seq(-20000, 20000, 10000), \n                     labels = paste0(as.character(c('20k','10k','0','10k','20k')))) +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\",hjust = 0.5),\n    plot.subtitle = element_text(size = 10, color = \"darkgrey\",hjust = 0.5),\n    strip.text.x = element_text(size = 9),\n    axis.text=element_text(size=6)\n  )\n\n\n\n\n\nThe pyramids of each PA is too narrow. We need to transform the Singapore population.\n\n\nsg_pop_bg <- sg_pop_bg %>%\n    mutate(\n    trans_pop = ifelse(Population == \"Null\", 0, 0.2 * Population)\n  )\nhead(sg_pop_bg,5)\n\n      Sex AGE Population trans_pop\n1 Females >90       1470       294\n2 Females >90        450        90\n3 Females >90        880       176\n4 Females >90        600       120\n5 Females >90        280        56\n\n\n\nvis <- ggplot(most_populatedPA_pop_data, \n       aes(x = AGE, y = Population, fill = Sex)) + \n  geom_bar(data = subset(sg_pop_bg, Sex == \"Females\"), aes(x = AGE, y = trans_pop), fill = \"grey\",stat = \"identity\") +\n  geom_bar(data = subset(sg_pop_bg, Sex == \"Males\"), aes(x = AGE, y = trans_pop), fill = \"grey\",stat = \"identity\") + \n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Females\"), stat = \"identity\") +\n  geom_bar(data = subset(most_populatedPA_pop_data, Sex == \"Males\"), stat = \"identity\") + \n  coord_flip()+\n  facet_wrap(~ PA,ncol = 3 ) +\n  labs(title=\"Age-sex Pyramids in 9 Most Populated PA, as of June 2022\", \n       subtitle = \"Bedok has the oldest age structure while Punggol has the youngest\",\n       x = \"Age Group\",y=\"Population\") +\n  scale_y_continuous(breaks = seq(-20000, 20000, 10000), \n                     labels = paste0(as.character(c('20k','10k','0','10k','20k')))) +\n  theme(\n    plot.title = element_text(size = 12, face = \"bold\",hjust = 0.5),\n    plot.subtitle = element_text(size = 10, color = \"darkgrey\",hjust = 0.5),\n    strip.text.x = element_text(size = 8),\n    axis.text=element_text(size=6)\n  )\nvis\n\n\n\n\nData Source: Department of Statistics, Singapore"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html",
    "title": "Take Home Exercise 03",
    "section": "",
    "text": "To uncover the salient patterns of the resale prices of 3-room, 4-room and 5-room public housing property by residential towns and estates in Singapore.\nWe will use appropriate analytically visualisation techniques as well as interactive techniques to enhance user and data discovery experiences.\nThe data can be downloaded here."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#transaction-volume",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#transaction-volume",
    "title": "Take Home Exercise 03",
    "section": "1. Transaction volume",
    "text": "1. Transaction volume\nLet us first study the number of resale HDBs of different flat types from Jan 2017 to Feb 2023.\n\n\nShow the code\np1 <- prop_data %>%\n  group_by(month) %>%\n  ggplot(mapping = aes(x = prop_data$month)) +\n  geom_bar_interactive(\n    aes(tooltip = prop_data$month)\n  )+\n  theme_bw()+\n  \n  labs(title = \"Monthly Sales Volume, from Jan 2017 to feb 2023\", x = 'Time', y = 'Monthly Sales Volume',\n       caption = \"Singapore circuit breaker measures · 2020-04-07 to 2020-06-01 (1 month, 3 weeks, and 4 days)\") +\n  \n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank()) +\n  geom_vline(aes(xintercept = '2020-04'),linetype = \"dashed\",color= 'red') +\n  geom_vline(aes(xintercept = '2022-01'),linetype = \"dashed\",color= 'blue') +\n  geom_vline(aes(xintercept = '2022-12'),linetype = \"dashed\",color= 'blue') +\n  \n  annotate(\"text\",label = \"Circuit Breaker\", x = \"2019-11\",y=1000) +\n  annotate(\"text\",label = \"2022\", x = \"2022-05\",y=1000)+\n  \n\n\n  facet_wrap(~flat_type, nrow = 3) \n  \ngirafe(\n  ggobj = p1,\n  width_svg = 6,\n  height_svg = 6 * 0.618\n)\n\n\n\n\n\n\nInteractivity: By hovering the mouse pointer on the bar of interest, the respective month will be displayed.\nFindings: During the 2 months of circuit breaker, the number of HDB resale flat transactions dropped 80% and recovered as soon as possible after the circular break ends. The volume of transactions resumed as soon as the circuit break ended.\nAmong the three flat types, the most popular type is the 4-room flats.\nIn 2022, the number of resale HDB peaks in September for all 3 types of HDB flats. In Feburary, the least number of HDBs been sold for all types. The reason might be due to the Spring Festival. Overall, the volume of transactions is quite stable compared with 2021."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#resale-price-of-different-flat-types",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#resale-price-of-different-flat-types",
    "title": "Take Home Exercise 03",
    "section": "2. Resale Price of different flat types",
    "text": "2. Resale Price of different flat types\n\na.Trend\n\nYearly2022\n\n\n\n\nShow the code\nprop_data_p2 <- prop_data %>%\n  separate(month, into = c(\"year\", \"month\"), sep = \"-\", convert = TRUE) %>%\n  group_by(flat_type,year) %>%\n  summarise(ave_price = round(median(resale_price),1),\n            transation_volume = n(),\n            mean_size = round(mean(floor_area_sqm),1))\n\ntooltip_p2 <- \n  c(paste( \"Flat type:\", prop_data_p2$flat_type,\n           \"\\n Median resale price:\" , prop_data_p2$ave_price,\n           \"\\n Transaction volume:\", prop_data_p2$transation_volume,\n           \"\\n Mean size (sqm):\", prop_data_p2$mean_size\n  \n))\n\np2 <-prop_data_p2 %>%\n  ggplot(aes(x = year, y = ave_price,colour = flat_type))+\n  geom_smooth(alpha = 0.1) +\n  geom_point_interactive(aes(tooltip = tooltip_p2),size = 5) +\n  theme_classic() +\n  scale_x_continuous(breaks = seq(2017,2023,by = 1),limits = c(2017,2023)) +\n  labs(title = \"Resale Price of HDBs from 2017 to 2023\", x = 'Year', y = 'Resale Price (SGD)')\n\ngirafe(\n  ggobj = p2,\n  width_svg = 12\n)\n\n\n\n\n\n\n\n\n\n\nShow the code\nprop_data_p2 <- prop_data %>%\n  separate(month, into = c(\"year\", \"month\"), sep = \"-\", convert = TRUE) %>%\n  filter(year == 2022) %>%\n  group_by(flat_type,month) %>%\n  summarise(ave_price = round(median(resale_price),1),\n            transation_volume = n(),\n            mean_size = round(mean(floor_area_sqm),1))\n\ntooltip_p2 <- \n  c(paste( \"Flat type:\", prop_data_p2$flat_type,\n           \"\\n Median resale price:\" , prop_data_p2$ave_price,\n           \"\\n Transaction volume:\", prop_data_p2$transation_volume,\n           \"\\n Mean size (sqm):\", prop_data_p2$mean_size\n  \n))\n\np2 <-prop_data_p2 %>%\n  ggplot(aes(x = month, y = ave_price,colour = flat_type))+\n  geom_smooth(alpha = 0.1) +\n  geom_point_interactive(aes(tooltip = tooltip_p2),size = 3) +\n  theme_classic() +\n  scale_x_continuous(breaks = seq(1,12,by = 1),limits = c(1,12)) +\n  labs(title = \"Resale Price of HDBs in 2022\", x = 'Month', y = 'Resale Price (SGD)')\n\ngirafe(\n  ggobj = p2,\n  width_svg = 12\n)\n\n\n\n\n\n\n\n\n\nInteractivity: By hovering the mouse pointer on the data point(solid dot on the lines) of interest, the tooltip will be displayed. The tooltip includes the derived statistics of the median resale price, transaction volume and mean size.\nFindings: The resale flat prices were relatively stable between 2017 and 2020. For 3-room HDB, the price decreased slightly from 2017 to 2019. Then the prices for all the 3 types began to rise from 2020. The difference of median transaction price between 3-room and 4-room is much larger than it between the 4-room and 5-room.\nIn 2022, the price of 5-room started to drop from October, while kept increasing of 3-room and 4-room.\n\n\nb.ANOVA test of median price\nDoes the mean of the price per sqm differ among different flat types in 2022? First, let us explore the distribution of the mean price per sqm for different flat types.\n\n\nShow the code\nprop_data_test1 <- prop_data %>%\n  separate(month, into = c(\"year\", \"month\"), sep = \"-\", convert = TRUE) %>%\n  filter(year ==2022) %>%\n  mutate(ave_price_per_sqm = round(resale_price/floor_area_sqm,1))\n\nprice_distribution <- prop_data_test1 %>%\n  ggplot(aes(x = ave_price_per_sqm,y = flat_type)) +\n  geom_density_ridges_gradient(color = 'white') +\n  scale_fill_viridis_c(option = \"C\") +\n  theme_ggstatsplot() +\n  labs(title = \"Distribution of Price\", \n       x = \"Mean of Price psm (SGD)\", \n       y = \"Flat Type\") \nprice_distribution\n\n\n\n\n\nAs the price per sqm of all three types skewed to left and does not follow a normal distribution, we use non-parametric anova test to compare the median of the price per sqm of 3 different flat types.\n\n\nShow the code\nt1 <- ggbetweenstats(\n  data = prop_data_test1,\n  x = flat_type,\n  y = ave_price_per_sqm,\n  type = \"np\",\n  mean.ci = TRUE,\n  pairwise.comparisons = TRUE,\n  pairwise.display = \"s\",\n  p.adjust.method = \"fdr\",\n  messages = FALSE\n)\n\nt1\n\n\n\n\n\nKruskal-Wallis test is a non-parametric method for testing whether samples originate from the same distribution. Null hypothesis assumes that the groups are from identical populations. Alternative hypothesis assumes that at least one group comes from a different population than the others.\nConclusion: From the pairwise test result, we can conclude that: 1. There is no difference between the median price per sqm of 3-room and 4-room. 2. There are differences between the median price per sqm of 3-room and 5-room, and of 4-room and 5-room."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#resale-price-psm-in-different-residential-towns",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#resale-price-psm-in-different-residential-towns",
    "title": "Take Home Exercise 03",
    "section": "3. Resale Price psm in different residential towns",
    "text": "3. Resale Price psm in different residential towns\n\na. Price in 2022\nPlot the static ridgelines to show the distribution of average price/psm of flats in 2022 in Singapore for each residential towns.\n\n\nShow the code\n p3<- prop_data %>%\n  separate(month, into = c(\"year\", \"month\"), sep = \"-\", convert = TRUE) %>%\n  filter(year ==2022) %>%\n  group_by(town) %>%\n  mutate(price_psm = resale_price/floor_area_sqm) %>%\n  ggplot(mapping = aes(x=price_psm, \n                       y = reorder(as.factor(town),-price_psm),\n                       fill = after_stat(x)\n                       )\n         ) +\n  geom_density_ridges_gradient( color = \"white\") +\n  scale_fill_viridis_c(option = \"C\") +\n  theme_bw() +\n  \n  theme(legend.position = \"none\") +\n  theme(panel.grid = element_blank()) +\n  labs(title = \"HDB resale prices by residential towns, 2022 Singapore \", \n       x = \"Price psm (SGD)\", \n       y = \"Planning Area\")\np3\n\n\n\n\n\nWe can conclude that the resale of HDB in the areas such as woodlands, choa chu kang, jurong west are transacted at lower average price. And the price clustered around the average of $4000 to $5000 psm.\nWhile the price of resale HDB in Bukit merah, queenstown and central area not only have a higher price, but also scattered from $6000 to $10000.\nIn general, HDBs in residential towns having lower price tend to have a lower variability.\n\n\nb. Animation of Price changes over time\nLet us animate it.\n\n\nShow the code\nani1 <- prop_data %>%\n  group_by(town) %>%\n  mutate(price_psm = resale_price/floor_area_sqm) %>%\n  mutate(date = as.Date(paste(month,\"-01\", sep=\"\"))) %>%\n  ggplot(mapping = aes(x=price_psm, \n                       y = reorder(as.factor(town),-price_psm),\n                       fill = after_stat(x)\n                       )\n         ) +\n  geom_density_ridges_gradient( color = \"white\") +\n  scale_fill_viridis_c(option = \"C\") +\n  theme_bw() +\n  \n  theme(legend.position = \"none\") +\n  theme(panel.grid = element_blank()) +\n  labs(title = \"HDB resale prices in {frame_time} Singapore\", \n       x = \"Price psm (SGD)\", y = \"\") +\n  \n  transition_time(date)\n  anim_save('price_animation.gif',ani1)\n\n\n\nFrom 2017 to 2020, the price is quite stable. Each curve stays at its original place. The shape of the curves with lower average price have much less change compares with those with higher average price.\nHowever, from 2020 onwards, the curve starts to move to right. The average price almost increases by $1000 from 2020 to 2023."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#features-of-the-hdbs-in-different-residential-towns",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#features-of-the-hdbs-in-different-residential-towns",
    "title": "Take Home Exercise 03",
    "section": "4. Features of the HDBs in Different Residential Towns",
    "text": "4. Features of the HDBs in Different Residential Towns\n\na. Age of flats\nLet us explore the remaining lease years of the HDB flats in different residential towns. The age of HDB flat = 99 years - remaining lease years.\n\n\nShow the code\nprop_data_p4<- prop_data %>%\n  mutate(age = 99-as.integer(substr(prop_data$remaining_lease,0,2))) %>%\n  separate(month, into = c(\"year\", \"month\"), sep = \"-\", convert = TRUE) %>%\n  filter(year ==2022) %>%\n  group_by(town)\n\ntooltip <- function(y, ymax, accuracy = .01) {   \n  mean <- scales::number(y, accuracy = accuracy) \n  sem <- scales::number(ymax - y, accuracy = accuracy) \n  paste(\"Mean Age:\", mean, \"+/-\", sem) \n}\n\ngg_point <- ggplot(data=prop_data_p4, \n                   aes(x = reorder(town,age)),\n) +\n  stat_summary(aes(y = age, \n                   tooltip = after_stat(  \n                     tooltip(y, ymax))),  \n    fun.data = \"mean_se\", \n    geom = GeomInteractiveCol,\n    fill = \"lightblue\"\n    \n  ) +\n  stat_summary(aes(y = age),\n    fun.data = mean_se,\n    geom = \"errorbar\", width = 0.2, size = 0.2\n  ) +\n  facet_wrap(~flat_type)+\n  coord_flip()+\n  theme_bw() +\n  \n  theme(legend.position = \"none\") +\n  theme(panel.grid = element_blank()) +\n  labs(title = \"Age of HDBs by residential towns, 2022 Singapore\", \n       y = \"Age (years)\", \n       x = \"Residential Town\") \n  #theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))\n\ngirafe(ggobj = gg_point,\n       width_svg = 8,\n       height_svg = 8*0.618)\n\n\n\n\n\n\nInteractivity: By hovering the mouse pointer on the bar of interest, the respective mean age and standard error of mean will be displayed.\nWe can conclude that the HDB at punggol, sengkang are relatively new compared with the flats in marine parade and bukit timah. Moreover, 3-room flats are older than 4-room and 5-room flats.\n\n\nb. Storey of flats\n\n\nShow the code\nprop_data_p5 <- prop_data %>%\n  separate(month, into = c(\"year\", \"month\"), sep = \"-\", convert = TRUE) %>%\n  filter(year ==2022) %>%\n  group_by(town,storey_range,flat_type) %>%\n  summarise(median_price = median(resale_price))\n\ntooltip_p5 <-  \n  c(paste( \"Town:\", prop_data_p5$town,\n           \"\\n Storey:\" , prop_data_p5$storey_range,\n           \"\\n Median Price:\",prop_data_p5$median_price\n))\n\np5 <-  prop_data_p5 %>%\n  ggplot(aes(x = reorder(town,median_price), y = storey_range, fill = median_price)) +\n  geom_tile_interactive(tooltip = tooltip_p5) +\n  scale_fill_gradient(low = \"lightblue\",high = \"darkblue\") +\n  theme_bw() +\n  labs(title = \"Median Resale Price against Storey Range in Different Towns, 2022 Singapore\", \n       x = \"Residential Town\", \n       y = \"Storey Range\") +\n  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +\n  theme(axis.text.x = element_text(color = rep(c('black','orange','black','red','black','red'), time = c(16,2,4,2,1,1)))) +\n  theme(axis.text.x = element_text(face = rep(c('plain','bold','plain','bold','plain','bold'), time = c(16,2,4,2,1,1))))\n  #facet_wrap(~flat_type,nrow = 1)\n\n\ngirafe(\n  ggobj = p5,\n  width_svg = 10,\n  height_svg = 10 * 0.618\n)\n\n\n\n\n\n\nInteractivity: By hovering the mouse pointer on the tile of interest, the tooltip will be displayed. The tooltip includes the town, story level and median resale price.\nFindings: In general, the higher tiles tend to have darker blue. It means that the high floor HDBs are transacted at higher price. The tallest HDB flats are located in central area, queenstown and bukit merah. Recall what we have discovered about the distribution of price in different residential towns. The three towns have the highest median price in the past 5 years.\nThere are two towns, marine parade and bukit timah, where color are darker compared to others. It means that the HDB flats located are the same floor level are sold at higher price compared to other towns."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#summary",
    "href": "Take-Home_Ex/Take-Home_Ex03/Take-Home_Ex03.html#summary",
    "title": "Take Home Exercise 03",
    "section": "Summary",
    "text": "Summary\nIn general:\n\nDuring circular break (2020 Apr to 2020 Jun), the volume of trasactions dropped 80% and resumed as soon as the circular break ends. The number of resale HDB flats transacted are slighter higher after circular break than it transacted before the circular break.\nThe price of resale HDBs were stable before 2020, and increased from 2020 to 2023.\nThe number of HDB flats sold was the highest in Sep 2022 and was the lowest in Feb 2022. The volume of transactions kept stable from 2021 to 2022.\n\nFor different flat types(3-room, 4-room, 5-room) :\n\nThe 4-rooms has the highest number of transaction.\nThe median price per sqm of 5 room is slightly lower than 3-room and 4-room.\nThe age of 3-room flats are the oldest.\n\nFor the flats in different residential town:\n\nIn Central Area, Queenstown and Bukit Merah: HDBs are the tallest and sold at the highest price.\nIn Centra Area, marine parade and Bukit Timah: HDBs are more expensive compared to others when they are at the same floor level.\nIn Punggol and Sengkang: many new HDBs are sold."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take_Home_Ex04.html",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take_Home_Ex04.html",
    "title": "Take Home Exercise 4 (Time Series)",
    "section": "",
    "text": "To uncover the impact of COVID-19 as well as the global economic and political dynamic in 2022 on Singapore bi-lateral trade (i.e.Import, Export and Trade Balance) by using appropriate analytical visualisation techniques.\nMerchandise Trade provided by Department of Statistics, Singapore (DOS) will be used. The study period should be between January 2020 to December 2022."
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take_Home_Ex04.html#data-preparation",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take_Home_Ex04.html#data-preparation",
    "title": "Take Home Exercise 4 (Time Series)",
    "section": "2. Data Preparation",
    "text": "2. Data Preparation\n\n2.1 Install R packages and Load Data\n\n\nShow the code\npacman::p_load(ggbraid,imager,readxl,lubridate,zoo,plotly,GGally,DT, patchwork,ggHoriPlot,CGPfunctions,gganimate,tmap,tmaptools,sf,tidyverse)\n\n\nNote that by default, read_excel will guess column types. We can provide them explicitly via the col_types argument.\n\n\nShow the code\n# define column types (ct): if starts with \"Data\" is text, or else if numeric.\nnms <- names(read_excel(\"data/SGTrade.xlsx\",sheet = \"T1\",range = cell_rows(10)))\nct <- ifelse(grepl(\"^Da\", nms), \"text\", \"numeric\")\nexport <- read_excel(\"data/SGTrade.xlsx\",sheet = \"T1\",range = cell_rows(10:101),col_types = ct)\nimport <- read_excel(\"data/SGTrade.xlsx\",sheet = \"T2\",range = cell_rows(10:129),col_types = ct)\n\n# can use the following to check the type of each column\n# sapply(import,mode)\n\n#filter dataset 2020Jan to 2022Dec.\nimport <- import %>%\n  select(c('Data Series','2022 Dec' : '2020 Jan'))\n\nexport <- export %>%\n  select(c('Data Series','2022 Dec' : '2020 Jan'))\n\n\nMerchandise Exports: Refer to all goods taken out of Singapore.\nMerchandise Imports: Refer to all goods brought into Singapore.\n\nExportImport\n\n\n\n\nShow the code\nDT::datatable(export, options = list(pageLength = 5))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nDT::datatable(import, options = list(pageLength = 5))\n\n\n\n\n\n\n\n\n\n\n\n\n2.2 Data Wrangling\n\nStep1\nThe code chunk below perform the necessary data wrangling to\n1. remove total and region by removing the first 7 rows\n2. rename the first column as country and remove the ‘(thousands dollars)’ behind each country name using regular expression. Note that () are special chars and need to be escaped with backslashes.\n\n\nShow the code\ncolnames(export)[1] <- \"country\" \nexport <- export %>%\n  #Keep country level data\n  filter(!row_number() %in% c(1:7)) %>% \n  #rename the country by removing the (Thousand Dollars)\n  mutate(country = str_replace_all(country,\"\\\\(|Thousand Dollars|\\\\)\",\"\"))\n\ncolnames(import)[1] <- \"country\" \nimport <- import %>%\n  #Keep country level data\n  filter(!row_number() %in% c(1:7)) %>% \n  #rename the country by removing the (Thousand Dollars)\n  mutate(country = str_replace_all(country,\"\\\\(|Thousand Dollars|\\\\)\",\"\"))\n\n\n\n\nStep2\nTo prepare time series friendly data, we need to transform tibbles.\n\nuse pivot_longer to get the timeseries data table\nconvert the current month to datetime type, hence easier to sort the data according to time\n\n\n\nShow the code\nexport_long <- export %>%\n  #create timeseries tibble\n  pivot_longer(cols = !country,names_to = \"month\",values_to = \"value\" ) %>%\n  # convert month to datetime\n  separate(month, into = c(\"year\", \"month_abb\"), sep = \" \", convert = TRUE) %>%\n  mutate(numeric_month = match(month_abb,month.abb)) %>%\n  mutate(Month = as.Date(as.yearmon(paste(year,numeric_month),\"%Y %m\"))) %>%\n  mutate(Value = value * 1000) %>%\n  select(country,Month,Value)\n#Order by time\nexport_long <- export_long[order(export_long$Month),]\n\n\n\nimport_long <- import %>%\n  #create timeseries tibble\n  pivot_longer(cols = !country,names_to = \"month\",values_to = \"value\" ) %>%\n  # convert month to datetime\n  separate(month, into = c(\"year\", \"month_abb\"), sep = \" \", convert = TRUE) %>%\n  mutate(numeric_month = match(month_abb,month.abb)) %>%\n  mutate(Month = as.Date(as.yearmon(paste(year,numeric_month),\"%Y %m\"))) %>%\n  mutate(Value = value * 1000) %>%\n  select(country,Month,Value)\n\nimport_long <- import_long[order(import_long$Month),]\n\n# Add column of type\nexport_long <- export_long %>%\n  add_column(\"type\" = \"export\")\nimport_long <- import_long %>%\n  add_column(\"type\" = \"import\")\n\n\nThe time series friendly table can be viewed as shown below.\n\nExportImport\n\n\n\n\nShow the code\nDT::datatable(export_long, options = list(pageLength = 5))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nDT::datatable(import_long, options = list(pageLength = 5))\n\n\n\n\n\n\n\n\n\n\n\n\nStep3\nThe size of import and export tables are different. In order to compare the export and import of the same country, we need to remove countries that does not appear in both tables. Let us first use full join to combine two tables and filter out the countries with at least one NA in import value or export value. Countries only in export:\n\n\nShow the code\ncountry <-full_join(export_long, import_long, by=c('country','Month'))\n\nexport_na <- country[is.na(country$Value.x),]\nimport_na <- country[is.na(country$Value.y),]\nunique(export_na$country)\n\n\n [1] \"Norway \"                             \"Liechtenstein \"                     \n [3] \"Netherlands Antilles \"               \"Panama \"                            \n [5] \"Bahamas \"                            \"Bermuda \"                           \n [7] \"French Guiana \"                      \"Grenada \"                           \n [9] \"Guatemala \"                          \"Honduras \"                          \n[11] \"Jamaica \"                            \"St Vincent & The Grenadines \"       \n[13] \"Trinidad & Tobago \"                  \"Anguilla \"                          \n[15] \"Other Countries In America \"         \"Nauru \"                             \n[17] \"Cocos Keeling Islands \"              \"French Southern Territories \"       \n[19] \"Norfolk Island \"                     \"Cook Islands \"                      \n[21] \"Kiribati \"                           \"Niue \"                              \n[23] \"Tuvalu \"                             \"Wallis & Fatuna Islands \"           \n[25] \"Micronesia \"                         \"Palau \"                             \n[27] \"South Sudan \"                        \"Commonwealth Of Independent States \"\n\n\nCountries only in import:\n\n\nShow the code\nunique(import_na$country)\n\n\ncharacter(0)\n\n\nWe can conclude that there are 28 countries that Singapore only imported from but did not export to them. Finally, let us create the Singapore import and export trade table, in long and wide, by excluding the 28 countries.\n\n\nShow the code\nexclude_country <- unique(export_na$country)\nsg_long <- rbind(export_long,import_long) %>%\n  filter(!country %in% exclude_country) %>%\n  mutate(country = trimws(as.character(country)))\nsg_wide <- pivot_wider(sg_long, names_from = type, values_from = Value)\n\n\n\nSG Trade LongSG Trade Wide\n\n\n\n\nShow the code\nDT::datatable(sg_long, options = list(pageLength = 5))\n\n\n\n\n\n\n\n\n\n\n\nShow the code\nDT::datatable(sg_wide, options = list(pageLength = 5))"
  },
  {
    "objectID": "Take-Home_Ex/Take-Home_Ex04/Take_Home_Ex04.html#visual-analytics",
    "href": "Take-Home_Ex/Take-Home_Ex04/Take_Home_Ex04.html#visual-analytics",
    "title": "Take Home Exercise 4 (Time Series)",
    "section": "3. Visual Analytics",
    "text": "3. Visual Analytics\n\n3.1.1 Overview of Singapore Trade Balance in 2020, 2021 and 2022\n\nStaticInteractive\n\n\n\n\nShow the code\ntotal_long <- sg_long %>%\n  group_by(Month,type) %>%\n  summarise(Value = sum(Value))\n\ntotal_wide <- sg_wide %>%\n  group_by(Month) %>%\n  summarise(import = sum(import),\n            export = sum(export))\n\np1 <- ggplot() +\n  geom_line(aes(Month, Value, color = type, linetype = type), linewidth = 1, data = total_long) +\n  geom_braid(aes(Month, ymin = import, ymax = export, fill = export < import), data = total_wide, alpha = 0.6) +\n  guides(linetype = \"none\", fill = \"none\") +\n  \n  \n  scale_y_continuous(\"Trade(in billion SGD)\", \n                     labels = function(x){paste0('$', abs(x/10^9))}) +\n\n  scale_x_date(limits = c(min(sg_long$Month),max(sg_long$Month)), \n               date_breaks = \"6 month\",\n               date_labels = \"%Y-%m\",\n               expand = c(0,1)) +\n  \n  labs(title = 'TOTAL MERCHANDISE TRADE, Singapore 2020 to 2022',\n       subtitle = 'Singapore had 3 years in a row with a trade surplus',\n       caption = 'The shaded red area indicates trade surplus (export > import).') +\n  \n  \n  annotate(geom = \"segment\", x = as.Date('2020-04-01'),xend = as.Date('2020-08-01'), \n           y = 39946596*10^3, yend = 55*10^9) +\n  annotate(geom = \"segment\", x = as.Date('2020-08-01'),xend = as.Date('2021-02-01'), \n           y = 55*10^9, yend = 47668437*10^3) +\n  annotate(geom = \"text\", x = as.Date('2020-08-11'), y = 58 * 10^9, \n           label = \"trade plunged in 2020\\n but recovered sharply in 2021\") +\n  \n  \n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", size = 18),\n        plot.subtitle = element_text(size = 12),\n        axis.text.x = element_text(angle = 30, hjust = 1))\np1\n\n\n\n\n\n\n\n\n\nShow the code\nggplotly(p1)\n\n\n\n\n\n\n\n\n\nSingapore has a 3 years in row of trade surplus. The trade plunnged in 2020 due to the travel restriction, but recovered sharply in 2021. In 2022 Feb, both import and export dropped and at the same time, the Russia-Ukraine War started. After the trading volume peaked at 3rd quarter of 2022, it started to drop untill the end of 2022.\n\n\n3.1.2 Trade Balance of Manually Picked Countries\nFirst, we plot the trade balance between singapore and each trade partner and save the image as jpep.\n\n\nShow the code\nplot <- function(cname){\n  country_long <- sg_long%>%\n    filter(country == cname)\n  country_wide <- sg_wide %>%\n    filter(country == cname)\n  country_wide\n  \n  ggplot() +\n  geom_line(aes(x = Month, y = Value, color = type, linetype = type), data = country_long) +\n  geom_braid(aes(Month, ymin = import, ymax = export, fill = export < import), data = country_wide, alpha = 0.6) +\n  guides(linetype = \"none\", fill = \"none\") +\n  scale_y_continuous(limits = c(0,10*10^9)\n                     #,\"Trade(in billion SGD)\"\n                     ,labels = function(x){paste0('$', abs(x/10^9),\"B\")}) +\n\n  scale_x_date(limits = c(min(sg_long$Month),max(sg_long$Month)), \n               date_breaks = \"12 month\",\n               date_labels = \"%Y-%m\",\n               expand = c(0,1)) +\n  \n  labs(title = paste(cname)\n       , y = \"\"\n       ,x = \"\"\n       #Add the following when you plot to save as jpeg\n       #,subtitle = ('Trade between Singapore and the partner 2020 to 2022')\n       #,caption = 'The shaded red area indicates trade surplus (export > import).\\nThe shaded blue area indicates trade deficit (export < import).'\n       ) +\n  theme_bw() +\n  theme(plot.title = element_text(face = \"bold\", size = 12),\n        plot.subtitle = element_text(size = 12),\n        axis.text.x = element_text(angle = 30, hjust = 1))\n  \n# Use the following code to plot for all countries, hence we can select which one we want to discuss.\n  #ggsave(paste(\"country_trade/\",cname,\".jpeg\"))\n#}\n\n# the following codes are run to save the trade balance of each country as image\n#countries <- unique(sg_long$country)\n#for (c in countries){\n  #plot(c)}\n}\n\n\nThe screenshot of all the countries are as shown below. Note that we fix the range of y-axis to compare the trading volume.\n\nLet us focus one a few representative trading partners.\n\n\nShow the code\n# Manually choose a few countries, carefully set the theme of each one\nmcn <- plot(\"Mainland China\") + theme(legend.position = \"none\")\nus <- plot(\"United States\")+ theme(legend.position = \"none\")+ theme(axis.text.y=element_blank(),axis.ticks.y=element_blank())\nkr <- plot(\"Republic Of Korea\")+ theme(legend.position = \"none\")+ theme(axis.text.y=element_blank(),axis.ticks.y=element_blank())\njp <- plot(\"Japan\")+ theme(legend.position = \"none\")+ theme(axis.text.y=element_blank(),axis.ticks.y=element_blank())\n\n\nmy <- plot(\"Malaysia\") + theme(legend.position = \"none\")\nhk <- plot(\"Hong Kong\")+ theme(legend.position = \"none\")+ theme(axis.text.y=element_blank(),axis.ticks.y=element_blank())\nindo <- plot(\"Indonesia\")+ theme(legend.position = \"none\") + theme(axis.text.y=element_blank(),axis.ticks.y=element_blank())\naus <- plot(\"Australia\")+ theme(axis.text.y=element_blank(),axis.ticks.y=element_blank())\n\n#use patchwork to combine\npatchwork <- (mcn|us|kr|jp)/(my|hk|indo|aus)\npatchwork + plot_annotation(\n  title = \"Singapore Merchandise Trade with Major Partners\",\n  subtitle = \"Export to Mainland China reached new high in 2021Q4 and 2022Q2, falled in 2022 Q3 and Q4\n  \\nExport to US, Korea and Japan did not recover to 2020 level\") &\n  theme(plot.title = element_text(face = \"bold\", size = 10),\n        plot.subtitle = element_text(size = 8),\n        axis.text.x = element_text(angle = 30, hjust = 1))\n\n\n\n\n\nAbove are 8 major trade partners with high trading volume. Mainland China is Singapore largest trading partner, and the export to Mainland China reached new high in 2021 Q4 and 2022 Q2, started to fall in 2022 Q3. Singapore’s export to US, Korea and Japan did not recovered to 2022 Level.\nSingapore had 3 years in a row of trade deficit with Malaysia, and had 3 years in a row of trade surplus with Hong Kong, Indonesia and Australia， where the trade surplus with Hong Kong is the greatest. Singapore has a much more consistent import from HongKong than the export to Hong Kong.\n\n\n3.2 Trade Balance of all countries by Horizon Plots\nIn the diagram above, we hand picked a few countries to show the comparison between import and export. How can we plot the massive time series of import and export of many countries?\nLet us use horizon plots to show the trend of all the countries.\n\n\nShow the code\n# Compute trade balance, i.e. difference between import and export\ntrade_balance <- sg_wide %>%\n  mutate(Balance = import - export) \n\n\n#As there are negative values in balance, we need to normalize them.  We need to use two colors two represent trade surplus(red) and trade deficit, but not how big are the difference between export and import.\n#Our goal is to set the minimum (or maximum negative value to be 0).\nnorm <- function(x) {\n  (x - min(x))/(max(x)-min(x))\n}\ntrade_balance <- trade_balance %>%\n  mutate(balance = norm(Balance))\n\n# Find top traders based on trading volume, add a rank column to the table\ntop_country <- sg_long %>%\n  group_by(country) %>%\n  summarise(total_volume = sum(Value)) %>%\n  filter(total_volume > 10^9) %>%\n  arrange(desc(total_volume))\ntop_country$rank <- 1:nrow(top_country)\ntop_country <- top_country %>%\n  mutate(Rank = str_replace(rank,\"\\\\d+\",purrr::as_mapper(~sprintf('%02d',as.numeric(.x)))))\n\n\n# Filter country in top_country with trading volumes more than $1B(10^9)\ntrade_balance <- trade_balance %>%\n  filter(country %in% top_country$country)\n\n\n# Left Join two tables, aim to add the rank column in the trade_balance table\ntrade_balance <- merge(x = trade_balance, y = top_country[,c(\"country\",\"Rank\")], by = \"country\", all.x = TRUE) \n\n#Note that the balance_point's balance is not 0. We need to calculate it when export = import.\nbalance_point <- \n  (0-min(trade_balance$Balance))/(max(trade_balance$Balance) - min(trade_balance$Balance))\n#balance_point = 0.6+\n\n# change the country name to rank + country name\ntrade_balance <- trade_balance %>%\n  mutate(r_country = paste(Rank,country)) %>%\n  select(-c(export,import,country,Balance, Rank))\n\n\nLet us draw the horizon plot. The table can be viewed in the second tabset.\n\nHorizon PlotTable\n\n\n\n\nShow the code\n hori <- trade_balance %>%\n  \n  #filter(country %in% top_country$country) %>%\n  ggplot() +\n  geom_horizon(aes(x = Month, y=balance), \n               origin = balance_point,\n               horizonscale = 6)+\n               \n  \n  facet_grid(r_country~.) +\n    theme_bw() +\n  scale_fill_hcl(palette = 'RdBu') +\n  theme(panel.spacing.y=unit(0, \"lines\"), strip.text.y = element_text(\n    size = 5, angle = 0, hjust = 0),\n    legend.position = 'none',\n    axis.text.y = element_blank(),\n    axis.text.x = element_text(size=7),\n    axis.title.y = element_blank(),\n    axis.title.x = element_blank(),\n    axis.ticks.y = element_blank(),\n    panel.border = element_blank()\n    ) +\n    scale_x_date(expand=c(0,0), date_breaks = \"3 month\", date_labels = \"%b%y\") +\n  labs(\n    title = \"Singapore's Trade Balance against major partners with volume more than $1B\",\n    subtitle = \"Singpore's Trade Voleme increased, but Surplus decreased\",\n    captions = \"Red: trade surplus; Blue: trade deficit\\nTrade partners are arranged by trade volumes\"\n  )\nhori\n\n\n\n\n\n\n\n\n\nShow the code\nDT::datatable(trade_balance, options = list(pageLength = 5))\n\n\n\n\n\n\n\n\n\n\nNote: the numeric values in front of the country name represent the rank of the total trading volumes (export + import).\nFirst impression of the diagram is that the color of either blue or red is darker on the right side. It means that the trade volume increased.\nHowever, The blue are darker on the right side than on the left side, hence we conclude Singapore trade surplus decreases. The conclusion is affected by import exceeds import happened in 01 Mainland China, 03 United States,07 Republic of Korea and 08 Japan.\nThere are also many single colored bars. It represents that the relationship(surplus or deficit) between Singapore and those top traders are consistent. Those trade partners including: 02 Malaysia, 04 Taiwan, 05 Hong kong, 06 Indonesia, 09 Thailand, 10 Vietnam and etc.\n\n\n3.3 Analyzing the change in export/import of selected country over time using slopegraph\nSlope graph is useful to emphasis on the changes of the measures over time. It is visually encoded by the slope of the line. The countries are arranged vertically and the change of the order reveals the ranking of countries with respect to the corresponding parameter.\n\n\nShow the code\n# Prepare the dataset with 3 parameters, import volume, export volume and trade balance for the year 2020 and 2022\nslope_yr<- sg_wide %>%\n  mutate(year = year(Month)) %>%\n  group_by(year,country) %>%\n  summarise(yr_import = as.integer(sum(import)/10^9),yr_export = as.integer(sum(export)/10^9),yr_bal = as.integer((sum(export) - sum(import))/10^9)) %>%\n  mutate(Year = factor(year, ordered = TRUE, levels = c(\"2020\",\"2021\",\"2022\"))) %>%\n  filter (Year == 2020 | Year == 2022) %>%\n  ungroup(Year) %>%\n  select(Year,country,yr_import,yr_export,yr_bal)\nslope_yr <- slope_yr[,-1]\n\n\n\nImportExportTrand Balance\n\n\n\n\nShow the code\n# Let us work on import first.\n# We will color code the slope line by black = no change in ranking, red = rank up, blue = rank down.\n\n#Rank in 2020\nct_imp_rank_2020 <- slope_yr %>%\n  filter(Year == 2020) %>%\n  arrange(desc(yr_import)) %>%\n  select(-c(yr_import,yr_export,yr_bal))\nct_imp_rank_2020$rank_2020_imp <- 1:nrow(ct_imp_rank_2020)\n\n#Rank in 2022\nct_imp_rank_2022 <- slope_yr %>%\n  filter(Year == 2022) %>%\n  arrange(desc(yr_import)) %>%\n  select(-c(yr_import,yr_export,yr_bal))\nct_imp_rank_2022$rank_2022_imp <- 1:nrow(ct_imp_rank_2022)\n\n#compute the change in rank\nimp_rank_chg <- merge(x = ct_imp_rank_2020[,c(\"country\",\"rank_2020_imp\")],y=ct_imp_rank_2022[,c(\"country\",\"rank_2022_imp\")],by = 'country')\nimp_rank_chg <- imp_rank_chg %>%\n  mutate(change = rank_2020_imp-rank_2022_imp) %>%\n  mutate(ave_rank = (rank_2020_imp+rank_2022_imp)/2)\n\n#Color code\nimport_country_choose <- imp_rank_chg %>%\n  filter((ave_rank < 10 | change > 5 | change < -5) & ave_rank < 30) %>%\n  mutate(country_color = ifelse(change == 0, 'black',ifelse(change > 0, 'red','blue')))\n\n# find some representative countries: average of the ranking in both years < 10, or the change in rank is greater than 5.\ncountry_import_slope <- unique(import_country_choose$country)\n\nimport_slope_data <- slope_yr %>%\n  filter(country %in% country_import_slope) \n\nimport_slope <- CGPfunctions::newggslopegraph(import_slope_data,\n                              Year,\n                              yr_import,\n                              country,\n                              LineColor = import_country_choose$country_color,\n                              Title = \"Import Ranking Change from 2020 to 2022\",\n                              SubTitle = \"Ranking of top 4 countries did not change \\n\n                              Korean and United Arab Emirate ranked up, the othres ranked down\",\n                              Caption = \"Black: rank does not change; red: ranked up; blue: ranked down\",\n                              DataTextSize = 3,\n  DataLabelFillColor = \"gray\",\n  DataLabelPadding = .2,\n  DataLabelLineSize = .5)\n  \n\nimport_slope\n\n\n\n\n\n\n\n\n\nShow the code\n# Let us work on import first.\n# We will color code the slope line by black = no change in ranking, red = rank up, blue = rank down.\n\n#Rank in 2020\nct_exp_rank_2020 <- slope_yr %>%\n  filter(Year == 2020) %>%\n  arrange(desc(yr_export)) %>%\n  select(-c(yr_import,yr_export,yr_bal))\nct_exp_rank_2020$rank_2020_exp <- 1:nrow(ct_exp_rank_2020)\n\n\n\n#Rank in 2022\nct_exp_rank_2022 <- slope_yr %>%\n  filter(Year == 2022) %>%\n  arrange(desc(yr_export)) %>%\n  select(-c(yr_import,yr_export,yr_bal))\nct_exp_rank_2022$rank_2022_exp<- 1:nrow(ct_exp_rank_2022)\n\n\n#compute the change in rank\nexp_rank_chg <- merge(x = ct_exp_rank_2020[,c(\"country\",\"rank_2020_exp\")],y=ct_exp_rank_2022[,c(\"country\",\"rank_2022_exp\")],by = 'country')\nexp_rank_chg <- exp_rank_chg %>%\n  mutate(change =  rank_2020_exp-rank_2022_exp) %>%\n  mutate(ave_rank = (rank_2020_exp+rank_2022_exp)/2)\n\n#Color code\nexport_country_choose <- exp_rank_chg %>%\n  filter((ave_rank < 10 | change > 5 | change < -5) & ave_rank < 30) %>%\n  mutate(country_color = ifelse(change == 0, 'black',ifelse(change > 0, 'red','blue'))) \n\n\n# find some representative countries: average of the ranking in both years < 10, or the change in rank is greater than 5.\ncountry_export_slope <- unique(export_country_choose$country)\n\n\nexport_slope_data <- slope_yr %>%\n  filter(country %in% country_export_slope)  \n\n\nexport_slope <- CGPfunctions::newggslopegraph(export_slope_data,\n                              Year,\n                              yr_export,\n                              country,\n                              LineColor = import_country_choose$country_color,\n                              Title = \"Export Ranking Change from 2020 to 2022\",\n                              SubTitle = \"Ranking of top 2 country/region did not change\\n\n                              Malaysia and Taiwan ranked up, others ranked down\",\n                              Caption = \"Black: rank does not change; red: ranked up; blue: ranked down\",\n                              DataTextSize = 3,\n  DataLabelFillColor = \"gray\",\n  DataLabelPadding = .2,\n  DataLabelLineSize = .5)\n  \n\nexport_slope\n\n\n\n\n\n\n\n\n\nShow the code\n# Let us work on import first.\n# We will color code the slope line by black = no change in ranking, red = rank up, blue = rank down.\n\n#Rank in 2020\nct_bal_rank_2020 <- slope_yr %>%\n  filter(Year == 2020) %>%\n  arrange(desc(yr_bal)) %>%\n  select(-c(yr_import,yr_export,yr_bal))\nct_bal_rank_2020$rank_2020_bal <- 1:nrow(ct_bal_rank_2020)\n\n#Rank in 2022\nct_bal_rank_2022 <- slope_yr %>%\n  filter(Year == 2022) %>%\n  arrange(desc(yr_bal)) %>%\n  select(-c(yr_import,yr_export,yr_bal))\nct_bal_rank_2022$rank_2022_bal <- 1:nrow(ct_bal_rank_2022)\n\n#compute the change in rank\nbal_rank_chg <- merge(x = ct_bal_rank_2020[,c(\"country\",\"rank_2020_bal\")],y=ct_bal_rank_2022[,c(\"country\",\"rank_2022_bal\")],by = 'country')\nbal_rank_chg <- bal_rank_chg %>%\n  mutate(change = rank_2020_bal-rank_2022_bal) %>%\n  mutate(ave_rank = (rank_2020_bal+rank_2022_bal)/2)\n\n#Color code\nbalance_country_choose <- bal_rank_chg %>%\n  filter((ave_rank < 6| change > 5 | change < -5) & ave_rank < 30) %>%\n  mutate(country_color = ifelse(change == 0, 'black',ifelse(change > 0, 'red','blue')))\n\n# find some representative countries: average of the ranking in both years < 10, or the change in rank is greater than 5.\ncountry_balance_slope <- unique(balance_country_choose$country)\n\nbalance_slope_data <- slope_yr %>%\n  filter(country %in% country_balance_slope) \n\nbalance_slope <- CGPfunctions::newggslopegraph(balance_slope_data,\n                              Year,\n                              yr_bal,\n                              country,\n                              LineColor = balance_country_choose$country_color,\n                              Title = \"Balance Ranking Change from 2020 to 2022\",\n                              SubTitle = \"Hong Kong has the greatest and most stable trade surplus\\nIndonesia's trade balance ranked up\",\n                              Caption = \"Black: rank does not change; red: ranked up; blue: ranked down\",\n                              DataTextSize = 3,\n  DataLabelFillColor = \"gray\",\n  DataLabelPadding = .2,\n  DataLabelLineSize = .5,\n  WiderLabels=TRUE)\n  \n\nbalance_slope\n\n\n\n\n\n\n\n\n\n\n3.4 Animate Trade Performance between Singapore and its partners using Bubble Chart\nFinally, let us animate the export and import of major partners from 2020 to 2022.\n\n\nShow the code\nbubble_data <- sg_wide %>%\n  mutate(monthly_export = round(export/10^9,2),\n         monthly_import = round(import/10^9,2),\n         balance = round(monthly_import - monthly_export,2),\n         monthly_total = round(monthly_export + monthly_import,2),\n         sur_def = ifelse(balance > 0, \"surplus\", \"deficit\")) %>%\n  select(Month,country,monthly_export,monthly_import,balance,monthly_total,sur_def)\n#Order by time\nbubble_data <- bubble_data[order(bubble_data$Month),]\n\nbubble_plot <- bubble_data %>%\n  filter(country %in% top_country$country[1:20]) %>%\n  ggplot(aes(x=monthly_export, y = monthly_import, size = monthly_total,  fill = sur_def)) +\n  geom_point(alpha = 0.8)+\n  geom_abline(intercept = 0,slope = 1) +\n  geom_label(aes(label = country)) +\n  theme_classic() +\n  theme(legend.position = 'none')+\n  labs(title = \"Merchandise Monthly Export vs Import from 2020 to 2022\",\n       subtitle = \"Month: {format(frame_time, '%b%Y')}\",\n       x = \"Export (Billion)\", y = \"Import (Billion)\") +\n  coord_equal() +\n  theme(plot.title = element_text(size = 12, face = \"bold\"),\n        plot.subtitle = element_text(size = 10),\n        axis.line.x = element_line(color=\"black\", size = 1),\n        axis.line.y = element_line(color=\"black\", size = 1),\n        axis.title.x = element_text(size = 12),\n        axis.title.y = element_text(size = 12),\n        axis.text.x = element_text(size = 10),\n        axis.text.y = element_text(size = 10))+\n  \n  transition_time(as.Date(Month)) +\n  shadow_wake(wake_length = 0.1, alpha = FALSE) +\n  ease_aes(\"linear\") \n\n\nbubble_ani<- animate(bubble_plot,fps = 10, duration = 30)\nanim_save('trade_animation_fps20.gif',bubble_ani)\n\n\n\nThe red color represent the trade surplus and the blue color represent the trade deficit. The straight line split the region into two parts, upper triangular area represents deficits where all the blue rectangular boxes locate.\nThe size of each rectangular box is proportional to the trading volume. We choosed 20 countries with highest trading volume from 2020 to 2022.\nThere are some countries/regions’ color did not change, such as Hongkong(red) at the right bottom, or Malaysia (blue) and Taiwan moved along the line.\nThere are some countries such as Mainland China, locates on the top right corner with large size. Before covid, the color of Mainland China is blue, and it stared to change to red in 2020 May.\nIn general, we feel that there are much more blue boxes from Mar 2022 onwards. And the boxes move to top right corner from 2020 to 2022. It means that the trade volumes increased, and the trade deficit also increased."
  }
]